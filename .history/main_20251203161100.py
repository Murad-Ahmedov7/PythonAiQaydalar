


# 1) HER BIRINE BIR NUMUNE YAZ NEZERI OLARAQ 
# 2) HER DERSIN SUAL-CAVABINA BAX.
# 3) 9-CU DERSIN QUIZINE YENIDEN BAX. 



#region PythonAi1
from statistics import variance

import numpy
import pandas as pd


# AI-nin (SÃ¼ni Ä°ntellektin) É™sas mÉ™qsÉ™di insanÄ±n intellektual fÉ™aliyyÉ™tlÉ™rini maÅŸÄ±nlara Ã¶yrÉ™tmÉ™k vÉ™ avtomatlaÅŸdÄ±rmaqdÄ±r.


#region #AI vs ML vs DL 
 
#Ai

# TÉ™rif:
# Ä°nsanÄ±n dÃ¼ÅŸÃ¼nmÉ™, qÉ™rarvermÉ™ vÉ™ problem hÉ™ll etmÉ™ qabiliyyÉ™tini kompÃ¼terdÉ™ tÉ™qlid edÉ™n sistemlÉ™rin Ã¼mumi adÄ±.

# BaÅŸqa sÃ¶zlÉ™:
# AÄŸÄ±llÄ± davranÄ±ÅŸ gÃ¶stÉ™rÉ™n hÉ™r bir proqram vÉ™ ya maÅŸÄ±n.


# 2. ML â€” Machine Learning (MaÅŸÄ±n Ã–yrÉ™nmÉ™si)
# AI-nin alt sahÉ™sidir

# TÉ™rif:
# KompÃ¼terin aÃ§Ä±q ÅŸÉ™kildÉ™ proqramlaÅŸdÄ±rÄ±lmadan, datalardan nÃ¼munÉ™ vÉ™ qaydalar Ã¶yrÉ™nÉ™rÉ™k qÉ™rar vermÉ™sini tÉ™min edÉ™n sÃ¼ni intellekt Ã¼sulu.

# BaÅŸqa sÃ¶zlÉ™:
# Model dataya baxÄ±b Ã¶zÃ¼ Ã¶yrÉ™nir vÉ™ nÉ™ticÉ™ verir.



# ğŸ”´ 3. DL â€” Deep Learning (DÉ™rin Ã–yrÉ™nmÉ™)

# ML-in alt sahÉ™sidir

# TÉ™rif:
# Ã‡oxqatlÄ± neyron ÅŸÉ™bÉ™kÉ™lÉ™rdÉ™n istifadÉ™ edÉ™rÉ™k, bÃ¶yÃ¼k vÉ™ kompleks datalar Ã¼zÉ™rindÉ™ avtomatik ÅŸÉ™kildÉ™ xÃ¼susiyyÉ™t Ã§Ä±xaran vÉ™ Ã¶yrÉ™nÉ™n maÅŸÄ±n Ã¶yrÉ™nmÉ™si metodu.

# BaÅŸqa sÃ¶zlÉ™:
# Beyin kimi Ã§alÄ±ÅŸan neyron ÅŸÉ™bÉ™kÉ™lÉ™ri ilÉ™ Ã¶yrÉ™nmÉ™.

#endregion





# region â­ 1. AI (SÃ¼ni Ä°ntellekt) É™sas anlayÄ±ÅŸlarÄ±

# AI-dÉ™ 5 É™sas qabiliyyÉ™t var:

# 1) Perception â€” Qavrama

# MaÅŸÄ±nÄ±n É™trafÄ± dÉ™rk etmÉ™si
# MÉ™s: kamera ilÉ™ ÅŸÉ™kli gÃ¶rmÉ™k, sÉ™si anlamaq

# 2) Reasoning â€” MÉ™ntiq

# TÉ™hlil edib qÉ™rar vermÉ™k
# MÉ™s: â€œÉ™gÉ™r yaÄŸÄ±ÅŸ yaÄŸÄ±rsa, Ã§É™tir gÃ¶tÃ¼rmÉ™liyÉ™mâ€.

# 3) Learning â€” Ã–yrÉ™nmÉ™k

# Datalardan qaydalar Ã§Ä±xarmaq
# MÉ™s: ML modellÉ™rinin Ã¶yrÉ™nmÉ™si

# 4) Planning â€” PlanlaÅŸdÄ±rmaq

# HÉ™dÉ™fÉ™ Ã§atmaq Ã¼Ã§Ã¼n addÄ±mlar seÃ§mÉ™k
# MÉ™s: naviqasiya xÉ™ritÉ™si É™n qÄ±sa yolu tapÄ±r

# 5) Action â€” ÆmÉ™l etmÉ™k

# Robotun hÉ™rÉ™kÉ™t etmÉ™si, sÉ™sli asssistantÄ±n cavab vermÉ™si

#endregion


# region â­ 2. AI-nin nÃ¶vlÉ™ri
# 1) Narrow AI (ZÉ™if AI)

# YalnÄ±z bir iÅŸi yerinÉ™ yetirir.
# MÉ™s:

# Siri

# Google Translate

# ChatGPT

# Face ID
# â¡ï¸ Bir sahÉ™dÉ™ gÃ¼clÃ¼dÃ¼r, amma Ã¼mumi zÉ™kasÄ± yoxdur.

# 2) General AI (Ãœmumi AI)

# Ä°nsan kimi hÉ™r mÃ¶vzuda dÃ¼ÅŸÃ¼nÉ™ bilÉ™n, Ã¶yrÉ™nÉ™ bilÉ™n AI.
# Bu hÉ™lÉ™ mÃ¶vcud deyil.

# 3) Super AI (SÃ¼per ZÉ™ka)

# Ä°nsanÄ± bÃ¼tÃ¼n sahÉ™lÉ™rdÉ™ keÃ§É™n AI.
# Bu da mÃ¶vcud deyil â€” nÉ™zÉ™ri anlayÄ±ÅŸdÄ±r.

#endregion



# region â­ 3. AI-nin É™sas sahÉ™lÉ™ri

# AI bir neÃ§É™ bÃ¶yÃ¼k sahÉ™yÉ™ bÃ¶lÃ¼nÃ¼r:

# Machine Learning (ML)

# Deep Learning (DL)

# Computer Vision (CV) â€” gÃ¶rÃ¼ntÃ¼ iÅŸlÉ™mÉ™

# NLP â€” Natural Language Processing

# Robotics

# Expert Systems

# Speech Recognition (sÉ™s tanÄ±ma)


#endregion


# region â­ 4. Adi proqramlaÅŸdÄ±rma vÉ™ ML fÉ™rqi
# Normal proqramlaÅŸdÄ±rma

# KompÃ¼terÉ™ qaydalarÄ± sÉ™n yazÄ±rsan.

# Rules + Data â†’ Output


# MÉ™s:
# ÆgÉ™r temperatura > 30 â†’ kondisioneri iÅŸÉ™ sal

# Machine Learning

# KompÃ¼ter qaydalarÄ± Ã¶z Ã§Ä±xarÄ±r.

# Data + Output â†’ Rules/model


# MÉ™s:
# TÉ™lÉ™bÉ™nin neÃ§É™ saat oxumasÄ±na baxÄ±b â€œneÃ§É™ bal alacaÄŸÄ±nÄ±â€ Ã¶yrÉ™nir.

#endregion


# region â­ 5. ML-in 3 nÃ¶vÃ¼(oyrenme novleri)
# ğŸ”µ 1. Supervised Learning (NÉ™zarÉ™tli Ã¶yrÉ™nmÉ™)

#feature-giris melumatlari

#target-cixis melumatlari

# Data + Target (doÄŸru cavab) var.

# MÉ™s:

# Studied	   Sleep	  Marks
# 5	          7	     80
# 2	          5	     50

# Model Ã¶yrÉ™nir: Ã§ox oxuyan â†’ Ã§ox bal alÄ±r.

# ğŸŸ¢ 2. Unsupervised Learning (NÉ™zarÉ™tsiz)

# YalnÄ±z data var, target yoxdur.
# Model qruplaÅŸdÄ±rÄ±r vÉ™ ya nÃ¼munÉ™ tapÄ±r.

# MÉ™s:

# 20 yaÅŸlÄ±lar Ã§ox xÉ™rclÉ™yir

# 45 yaÅŸlÄ±lar az xÉ™rclÉ™yir

# Model Ã¶zÃ¼ â€œklasterâ€ yaradÄ±r.

# ğŸ”´ 3. Reinforcement Learning (GÃ¼clÉ™ndirici Ã¶yrÉ™nmÉ™)

# Agent Ã§evrÉ™ ilÉ™ qarÅŸÄ±lÄ±qlÄ± É™laqÉ™dÉ™ Ã¶yrÉ™nir.
# DÃ¼z etsÉ™ â€” mÃ¼kafat
# SÉ™hv etsÉ™ â€” cÉ™za

# MÉ™s:

# Åahmat oynayan AI

# Ã–z-Ã¶zÃ¼nÉ™ sÃ¼rÉ™n maÅŸÄ±n

#endregion


# region â­ 6. AÃ§ar anlayÄ±ÅŸlar
# Feature â€” giriÅŸ parametri

# MÉ™s: yaÅŸ, saat, gÉ™lir

# Label â€” target (doÄŸru cavab)

# MÉ™s: bal, xÉ™stÉ™lik var/yox

# Model

# Ã–yrÉ™dilmiÅŸ nÃ¼munÉ™.
# MÉ™s: tÉ™lÉ™bÉ™nin balÄ±nÄ± proqnoz edÉ™n model.

# Prediction

# Modelin verdiyi cavab.
# MÉ™s: â€œ70 bal alacaqâ€.

# Accuracy

# Modelin dÉ™qiqliyi (faizlÉ™)


#endregion


#region â­ 7. ANN â€” Artificial Neural Network

# Ä°nsanÄ±n beynindÉ™n ilhamlanan model:(insan beyni neyronlarindan)

# neyronlardan ibarÉ™tdir

# baÄŸlantÄ±larla mÉ™lumat Ã¶tÃ¼rÃ¼r

# DL-in É™sasÄ±nÄ± tÉ™ÅŸkil edir

#endregion


#regionâ­ 8. DL â€” DÉ™rin Ã¶yrÉ™nmÉ™

# GÃ¼clÃ¼ tÉ™rÉ™flÉ™ri:

# Avtomatik feature extraction (Ã¶z-Ã¶zÃ¼nÉ™ dÃ¼zgÃ¼n xÃ¼susiyyÉ™tlÉ™ri tapÄ±r)

# Kompleks datanÄ± baÅŸa dÃ¼ÅŸÃ¼r (ÅŸÉ™kil, sÉ™s, mÉ™tn)

# Ã‡ox bÃ¶yÃ¼k datalarda Ã§ox dÉ™qiq nÉ™ticÉ™ verir

# ZÉ™if tÉ™rÉ™flÉ™ri:

# Ã‡ox gÃ¼clÃ¼ hesablama tÉ™lÉ™b edir (GPU)

# Ã‡ox data lazÄ±mdÄ±r

# â€œQara qutuâ€ problem â€” model niyÉ™ belÉ™ qÉ™rar verdi, aydÄ±n olmur

#endregion




# region 1ï¸âƒ£ Æsas kitabxanalar

# NumPy (np) â†’ É™dÉ™di hesablamalar, massivlÉ™r

# Pandas (pd) â†’ DataFrame ilÉ™ iÅŸlÉ™mÉ™k

# statistics â†’ sadÉ™ statistik funksiyalar (mode, variance)

#endregion


# region 2ï¸âƒ£ List vs DataFrame

# XÃ¼susiyyÉ™t	List	DataFrame
# Tip	Eyni strukturlu sadÉ™ data	CÉ™dvÉ™l formasÄ± (sÉ™tir+sÃ¼tun)
# Ä°stifadÉ™	KiÃ§ik dataset	BÃ¶yÃ¼k dataset vÉ™ analiz
# ÃœstÃ¼nlÃ¼k	SadÉ™	SÃ¼rÉ™tli, etiketli, Ã§ox funksiyalÄ±

#endregion



# region 3ï¸âƒ£ Pandas â€“ É™sas É™mrlÉ™r

# df.head() â†’ ilk sÉ™tirlÉ™r

# df.tail() â†’ son sÉ™tirlÉ™r

# df.sample() â†’ tÉ™sadÃ¼fi sÉ™tir

# df.info() â†’ struktur, tiplÉ™r

# df.describe() â†’ statistik xÃ¼lasÉ™

# SÃ¼tun seÃ§imi â†’ df['Col'], df[['A','B']]

# Filtr â†’ df[df['Rooms'] >= 3]


#endregion

#region  4ï¸âƒ£ Æsas statistik gÃ¶stÉ™ricilÉ™r


# Mean â†’ np.mean() â†’ É™dÉ™di orta

# Median â†’ np.median() â†’ ortadakÄ± dÉ™yÉ™r

# Mode â†’ mode() â†’ É™n Ã§ox tÉ™krarlanan

# Variance (Dispersiya) â€“ mÉ™lumatlarÄ±n orta dÉ™yÉ™rdÉ™n(mean-den) nÉ™ qÉ™dÉ™r uzaqlaÅŸdÄ±ÄŸÄ±nÄ± Ã¶lÃ§É™n statistik gÃ¶stÉ™ricidir.

# Std (Standart sapma) â†’ variance-in kvadrat kÃ¶kÃ¼

# KiÃ§ik std â†’ dÉ™yÉ™rlÉ™r sÄ±x

# BÃ¶yÃ¼k std â†’ dÉ™yÉ™rlÉ™r yayÄ±lmÄ±ÅŸ


# KiÃ§ik std â†’ mÉ™lumat sÄ±x, oxÅŸar

# BÃ¶yÃ¼k std â†’ mÉ™lumat yayÄ±lmÄ±ÅŸ, fÉ™rqli

#endregion



# region 5ï¸âƒ£ Outlier (SÄ±radan Ã§Ä±xan dÉ™yÉ™rlÉ™r)

# Outlier (SÄ±radan Ã§Ä±xan dÉ™yÉ™r) â€“ digÉ™r mÉ™lumatlardan xeyli fÉ™rqlÉ™nÉ™n, Ã§ox yÃ¼ksÉ™k vÉ™ ya Ã§ox aÅŸaÄŸÄ± olan dÉ™yÉ™rdir.



# MÉ™lumat: [1, 3, 5, 7, 9]
#
# Q1 (1-ci kvartil, 25%) â†’ mÉ™lumatÄ±n aÅŸaÄŸÄ± 25%-i
#
# Q1 = 3
#
# Q2 (2-ci kvartil, 50%) â†’ median / orta nÃ¶qtÉ™
#
# Q2 = 5
#
# Q3 (3-cÃ¼ kvartil, 75%) â†’ mÉ™lumatÄ±n yuxarÄ± 25%-i
#
# Q3 = 7



# q1=houses['Price_AZN'].quantile(0.25)
# q3=houses['Price_AZN'].quantile(0.75)
# print(q1)
# print(q3)
# iqr=q3-q1
# lower,upper=q1-1.5*iqr,q3+1.5*iqr
# iqr_outliers=houses[(houses['Price_AZN']<lower) | (houses['Price_AZN']>upper)]
# print(iqr_outliers)


# Ä°zah:
# DigÉ™r dÉ™yÉ™rlÉ™rdÉ™n Ã§ox yÃ¼ksÉ™k vÉ™ ya aÅŸaÄŸÄ± olan nÃ¶qtÉ™lÉ™r.

#endregion



#region 6ï¸âƒ£  Pandas É™mÉ™liyyatlarÄ±:
# a) DataFrame yaratmaq:
# df = pd.DataFrame({
#    'City': ['Baku', 'Ganja', 'Sumqayit'],
#    'Population': [2300000, 330000, 340000]
# })

# b) BaxÄ±ÅŸ É™mrlÉ™ri:
# print(df)           # bÃ¼tÃ¼n cÉ™dvÉ™li gÃ¶stÉ™rir
# print(df.head(2))   # ilk 2 sÉ™tri gÃ¶stÉ™rir
# print(df.tail(1))   # sonuncu sÉ™tri gÃ¶stÉ™rir
# print(df.sample())  # tÉ™sadÃ¼fi bir sÉ™tri gÃ¶stÉ™rir

# c) Ãœmumi mÉ™lumat:
# df.info()       # sÃ¼tunlarÄ±n tipi, boÅŸ dÉ™yÉ™rlÉ™r vÉ™ s.
# df.describe()   # statistik xÃ¼lasÉ™ (mean, std, min, max, vÉ™ s.)



#endregion



#region kod numunesi

# df=pd.DataFrame({
#    'City':['Baku','Ganja','Sumqayit'],
#    'Population':[2300000,330000,340000]
# })


# df["Population"]=df["Population"].astype('int64')
# df['Density_guess']=df['Population']/100

#endregion






#endregion


#region PythonAi2

import numpy as np
import pandas as pd


#  region 1ï¸âƒ£ NumPy

# Ä°stifadÉ™: Matris É™mÉ™liyyatlarÄ±, element-wise riyazi hesablamalar, sÃ¼rÉ™tli kod

# import numpy as np
# matrix = np.array([[1,2,3],[4,5,6],[7,8,9]])
# print(matrix*2)  # hÉ™r elementi 2 ilÉ™ vurur


# Random:

# np.random.normal(mean, std, size)    # Gaussian paylanma
# np.random.uniform(low, high, size)   # Uniform paylanma



# 1ï¸âƒ£ Normal (Gaussian) paylanma

# TÉ™rif: DÉ™yÉ™rlÉ™rin Ã§oxu orta É™trafÄ±nda cÉ™mlÉ™ÅŸÉ™n, kÉ™narlarda isÉ™ nadir hallarda olan paylanmadÄ±r.

# Forma: Bell-shaped (zÉ™ng ÅŸÉ™killi)

# NumPy: np.random.normal(mean, std, size)

# Ä°stifadÉ™: Statistik analiz, real hÉ™yat modellÉ™ri, Ã¶lÃ§Ã¼mlÉ™rin vÉ™ sÉ™hvlÉ™rin paylanmasÄ±

# 2ï¸âƒ£ Uniform (BÉ™rabÉ™r) paylanma

# TÉ™rif: VerilÉ™n aralÄ±qdakÄ± bÃ¼tÃ¼n É™dÉ™dlÉ™rin eyni ehtimalla meydana gÉ™ldiyi paylanmadÄ±r.

# Forma: Flat (dÃ¼zbucaqlÄ±)

# NumPy: np.random.uniform(low, high, size)

# Ä°stifadÉ™: TÉ™sadÃ¼fi seÃ§im, simulasiya, oyunlar

#endregion



# region 2ï¸âƒ£ Korrelyasiya & Kovariasiya



# 1ï¸âƒ£ Covariance (cov()) â€“ Kovariasiya

# TÉ™rif: Ä°ki dÉ™yiÅŸÉ™nin birlikdÉ™ necÉ™ dÉ™yiÅŸdiyini gÃ¶stÉ™rÉ™n statistik Ã¶lÃ§Ã¼dÃ¼r.

# MÃ¼sbÉ™t dÉ™yÉ™r: Bir dÉ™yiÅŸÉ™n artanda digÉ™ri dÉ™ artÄ±r.

# MÉ™nfi dÉ™yÉ™r: Bir dÉ™yiÅŸÉ™n artanda digÉ™ri azalÄ±r.

# Qeyd: Ã–lÃ§Ã¼lÉ™rÉ™ baÄŸlÄ±dÄ±r, mÃ¼qayisÉ™ etmÉ™k Ã§É™tindir.

# NumunÉ™:

# import pandas as pd

# data = {'X': [1, 2, 3], 'Y': [2, 4, 6]}
# df = pd.DataFrame(data)

# print(df.cov())


# NÉ™ticÉ™:

#       X    Y
# X   1.0  2.0
# Y   2.0  4.0


# X vÉ™ Y â†’ mÃ¼sbÉ™t kovariasiya â†’ birlikdÉ™ artÄ±r.

# 2ï¸âƒ£ Correlation (corr()) â€“ Korrelyasiya

# TÉ™rif: Ä°ki dÉ™yiÅŸÉ™nin xÉ™tti É™laqÉ™sinin gÃ¼cÃ¼nÃ¼ vÉ™ istiqamÉ™tini Ã¶lÃ§É™n statistik gÃ¶stÉ™ricidir.

# DÉ™yÉ™r aralÄ±ÄŸÄ±: -1 â€¦ +1

# MÃ¼sbÉ™t dÉ™yÉ™r: Bir dÉ™yiÅŸÉ™n artanda digÉ™ri dÉ™ artÄ±r.

# MÉ™nfi dÉ™yÉ™r: Bir dÉ™yiÅŸÉ™n artanda digÉ™ri azalÄ±r.

# 0: HeÃ§ bir xÉ™tti É™laqÉ™ yoxdur.

# Qeyd: Ã–lÃ§Ã¼lÉ™rdÉ™n asÄ±lÄ± deyil, mÃ¼qayisÉ™ etmÉ™k rahatdÄ±r.

# NumunÉ™:

# print(df.corr())


# NÉ™ticÉ™:

#      X    Y
# X  1.0  1.0
# Y  1.0  1.0


# X vÉ™ Y â†’ +1 â†’ mÃ¼kÉ™mmÉ™l mÃ¼sbÉ™t xÉ™tti É™laqÉ™

# ğŸ’¡ QÄ±sa fÉ™rq:

# cov() â†’ birlikdÉ™ necÉ™ dÉ™yiÅŸir (Ã¶lÃ§Ã¼lÉ™rÉ™ baÄŸlÄ±)

# corr() â†’ É™laqÉ™nin gÃ¼cÃ¼ vÉ™ istiqamÉ™ti (-1 â€¦ +1, Ã¶lÃ§Ã¼dÉ™n asÄ±lÄ± deyil)


#endregion



# region 3ï¸âƒ£Vizualizasiya
# import matplotlib.pyplot as plt
# import seaborn as sns

# # Histogram
# plt.hist(df['Price'], bins=20); plt.show()

# # Heatmap (Correlation)
# sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm'); plt.show()

# # Scatter + Trend line
# sns.lmplot(data=df, x="Area", y="Price", line_kws={"color":"red"}); plt.show()


# Histogram: qiymÉ™t paylanmasÄ±

# Heatmap: dÉ™yiÅŸÉ™nlÉ™rin qarÅŸÄ±lÄ±qlÄ± É™laqÉ™si

# Scatter + Trend line: iki dÉ™yiÅŸÉ™n arasÄ±ndakÄ± É™laqÉ™

#endregion



#endregion


#region PythonAi3

#region ğŸ“˜ Data Science - MÉ™qsÉ™d vÉ™ MÉ™rhÉ™lÉ™lÉ™r

# Data Science (MÉ™lumat Elmi) â€” mÃ¼xtÉ™lif mÉ™nbÉ™lÉ™rdÉ™n toplanan bÃ¶yÃ¼k hÉ™cmli mÉ™lumatlarÄ± 
# tÉ™hlil edib, onlarÄ± tÉ™mizlÉ™yib, modellÉ™ÅŸdirÉ™rÉ™k nÃ¼munÉ™lÉ™r, tendensiyalar vÉ™ faydalÄ± nÉ™ticÉ™lÉ™r Ã§Ä±xarmaÄŸa yÃ¶nÉ™lmiÅŸ elmi vÉ™ praktik sahÉ™dir.
# MÉ™qsÉ™d, mÉ™lumatlara É™saslanaraq qÉ™rar vermÉ™k, proqnozlaÅŸdÄ±rmaq vÉ™ problemlÉ™ri hÉ™ll etmÉ™kdir.

# MÉ™rhÉ™lÉ™lÉ™ri qÄ±sa olaraq:
# 1ï¸âƒ£ Toplama (Collect) â€“ mÉ™lumatlarÄ± yÄ±ÄŸmaq.
# 2ï¸âƒ£ TÉ™mizlÉ™mÉ™ vÉ™ hazÄ±rlama (Clean & Preprocess) â€“ mÉ™lumatÄ± iÅŸlÉ™k vÉ™ dÃ¼zgÃ¼n hala gÉ™tirmÉ™k.
# 3ï¸âƒ£ ModellÉ™ÅŸdirmÉ™ (Model / Analyze) â€“ analiz vÉ™ proqnoz Ã¼Ã§Ã¼n modellÉ™r qurmaq.
# 4ï¸âƒ£ Test etmÉ™k vÉ™ qiymÉ™tlÉ™ndirmÉ™k (Evaluate) â€“ modellÉ™rin dÃ¼zgÃ¼nlÃ¼yÃ¼nÃ¼ yoxlamaq.
# 5ï¸âƒ£ Ä°stifadÉ™yÉ™ vermÉ™k (Deploy / Operationalize) â€“ real vÉ™ziyyÉ™tdÉ™ tÉ™tbiq etmÉ™k, qÉ™rar dÉ™stÉ™yi Ã¼Ã§Ã¼n istifadÉ™ etmÉ™k.

#endregion




#region ğŸ“— Profiling - Avtomatik Dataset Analizi

# import pandas as pd
# import numpy as np
# from ydata_profiling import ProfileReport

# # Excel faylÄ±nÄ± oxu
# houses = pd.read_excel("houses_day.xlsx")

# # BoÅŸ dÉ™yÉ™rlÉ™rin yoxlanmasÄ±
# print("Floor null count:", houses['Floor'].isnull().sum())

# # Median ilÉ™ doldurmaq
# houses['DistanceToMetro_km'].fillna(houses['DistanceToMetro_km'].median(), inplace=True)

# # SÉ™tirlÉ™rdÉ™ boÅŸ District olanlarÄ± sil
# houses.dropna(subset=['District'], inplace=True)

# # Floor sÃ¼tununu rÉ™qÉ™mÉ™ Ã§evir
# houses['Floor'] = pd.to_numeric(houses['Floor'], errors='coerce')

# # ? iÅŸarÉ™lÉ™rini NaN ilÉ™ É™vÉ™zlÉ™
# houses.replace("?", np.nan, inplace=True)

# # DublikatlarÄ± sil
# houses.drop_duplicates(inplace=True)

# # Rayon Ã¼zrÉ™ orta qiymÉ™t hesabla
# avg_by_district = houses.groupby('District')['Price_AZN'].mean().round(2)

# # HÉ™r evin qiymÉ™tinin orta qiymÉ™tÉ™ nisbÉ™t fÉ™rqini faizlÉ™ É™lavÉ™ et
# houses['price_vs_mean'] = ((houses['Price_AZN'] / houses['District'].map(avg_by_district)) - 1) * 100

# # Profiling hesabatÄ±
# report = ProfileReport(houses, title="Houses Day Report", explorative=True)
# report.to_file("houses_day.html")

# # ğŸ”¹ Profiling (mÉ™lumat profillÉ™ÅŸdirmÉ™) â€“ datasetin avtomatik analiz edilmÉ™si vÉ™ 
# # xÃ¼lasÉ™ hesabatÄ±nÄ±n hazÄ±rlanmasÄ± prosesidir.


#endregion




#endregion


#region PythonAi4 Notbukdadi

#endregion

#region PythonAi5 Notbukdadi

#endregion


#region PythonAi6


# # Distribution (Paylanma) â€” verilÉ™nlÉ™rin vÉ™ ya ehtimallarÄ±n hansÄ± dÉ™yÉ™rlÉ™r arasÄ±nda vÉ™ hansÄ± tezliklÉ™ yayÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶stÉ™rÉ™n statistik anlayÄ±ÅŸdÄ±r.



# # | Paylanma nÃ¶vÃ¼    | ÅÉ™kil           | Æsas xÃ¼susiyyÉ™t              |
# # | ---------------- | --------------- | ---------------------------- |
# # | **Normal**       | ğŸ”” ZÉ™ng formalÄ± | Simmetrik, orta dÉ™yÉ™rlÉ™r Ã§ox |
# # | **Uniform**      | â–­ DÃ¼z           | HÉ™r dÉ™yÉ™r bÉ™rabÉ™r ehtimallÄ±  |
# # | **Poisson**      | ğŸ“‰ SaÄŸ É™yilmiÅŸ  | Nadir hadisÉ™lÉ™rin sayÄ±       |
# # | **Right-skewed** | â†˜ SaÄŸ quyruqlu  | Ã‡ox kiÃ§ik, az bÃ¶yÃ¼k dÉ™yÉ™rlÉ™r |
# # | **Left-skewed**  | â†™ Sol quyruqlu  | Ã‡ox bÃ¶yÃ¼k, az kiÃ§ik dÉ™yÉ™rlÉ™r |



# # ğŸ“Š 1. Normal Distribution (Normal paylanma)

# # ğŸ“ˆ ÅÉ™kli: ZÉ™ng (bell) formasÄ±nda, simmetrik.

# # Ortada É™n Ã§ox dÉ™yÉ™rlÉ™r var.

# # Uclarda (az vÉ™ Ã§ox) az dÉ™yÉ™rlÉ™r olur.

# # âœ¨ XÃ¼susiyyÉ™tlÉ™r:

# # Mean = Median = Mode

# # Data â€œortaâ€ É™trafÄ±nda yÄ±ÄŸÄ±lÄ±r.

# # Statistikada vÉ™ Machine Learning-dÉ™ É™n Ã§ox istifadÉ™ olunan paylanmadÄ±r.



# # ğŸ“Š 2. Uniform Distribution (BÉ™rabÉ™r paylanma)

# # ğŸ“ˆ ÅÉ™kli: DÃ¼z xÉ™tt â€” bÃ¼tÃ¼n dÉ™yÉ™rlÉ™rin eyni ehtimalÄ± var.

# # âœ¨ XÃ¼susiyyÉ™tlÉ™r:

# # HÉ™r nÉ™ticÉ™ eyni ÅŸansla baÅŸ verir.

# # â€œTam É™dalÉ™tliâ€ tÉ™sadÃ¼f hadisÉ™si.


# # ğŸ“Š 3. Poisson Distribution (Puasson paylanmasÄ±)

# # ğŸ“ˆ ÅÉ™kli: SaÄŸ tÉ™rÉ™fÉ™ É™yilmiÅŸ (right-skewed).

# # Nadir, amma baÅŸ verÉ™ bilÉ™n hadisÉ™lÉ™rin paylanmasÄ± Ã¼Ã§Ã¼n istifadÉ™ olunur.

# # Diskret (tam É™dÉ™dlÉ™rlÉ™ iÅŸlÉ™yir).

# # âœ¨ XÃ¼susiyyÉ™tlÉ™r:

# # â€œHadisÉ™lÉ™rin sayÄ±â€na baxÄ±r (vaxt vÉ™ ya mÉ™kan daxilindÉ™).

# # NÉ™ticÉ™lÉ™r 0, 1, 2, 3 kimi olur (say).


# # ğŸ“Š 4. Right-Skewed Distribution (SaÄŸa É™yilmiÅŸ paylanma)

# # ğŸ“ˆ ÅÉ™kli: Qrafikin quyruÄŸu saÄŸ tÉ™rÉ™fÉ™ uzanÄ±r.
# # YÉ™ni Ã§ox dÉ™yÉ™rlÉ™r kiÃ§ik, amma bir neÃ§É™ bÃ¶yÃ¼k dÉ™yÉ™r var.

# # âœ¨ XÃ¼susiyyÉ™tlÉ™r:

# # Mean > Median > Mode

# # Outlier-lar (bÃ¶yÃ¼k dÉ™yÉ™rlÉ™r) saÄŸdadÄ±r.



# # ğŸ“Š 5. Left-Skewed Distribution (Sola É™yilmiÅŸ paylanma)

# # ğŸ“ˆ ÅÉ™kli: Quyruq sol tÉ™rÉ™fÉ™ uzanÄ±r.
# # YÉ™ni Ã§ox dÉ™yÉ™rlÉ™r bÃ¶yÃ¼k, amma bir neÃ§É™ kiÃ§ik dÉ™yÉ™r var.

# # âœ¨ XÃ¼susiyyÉ™tlÉ™r:

# # Mean < Median < Mode

# # Outlier-lar (kiÃ§ik dÉ™yÉ™rlÉ™r) soldadÄ±r.


# import numpy as np
# import matplotlib.pyplot as plt
# import pandas as pd


# # house_room_count=np.random.normal(loc=4,scale=1,size=1000)

# # # print(house_room_count)

# # plt.hist(house_room_count,bins=20,color='skyblue',edgecolor='black')

# # plt.title('Normal distribution typical house rooms')
# # plt.xlabel('Room Count')
# # plt.ylabel('House Count')
# # plt.show()



# # house_room_count=np.random.uniform(low=1, high=6, size=1000)

# # # print(house_room_count)
# # #
# # plt.hist(house_room_count,bins=10,color='skyblue',edgecolor='black')
# # plt.xlabel('Room Count')
# # plt.ylabel('House Count')
# # plt.show()

# # # bins=20
# # # HistogramÄ±n sÃ¼tun sayÄ±nÄ± gÃ¶stÉ™rir (20 sÃ¼tun)




# house_room_count=np.random.poisson(2,size=1000)

# print(house_room_count)

# plt.hist(house_room_count,bins=range(0,10),color='salmon',edgecolor='black')
# plt.title("Poisson distribution")
# plt.xlabel("House Count")
# plt.ylabel("Room Count")
# plt.show()

# import numpy as np
# import matplotlib.pyplot as plt
# import pandas as pd
# from scipy.stats import normaltest, stats, poisson, chisquare

# # ------------------------------
# #        POISSON P AYLANMA
# # ------------------------------

# house_room_count = np.random.poisson(2, size=1000)

# plt.hist(house_room_count, bins=range(0, 10), edgecolor='black')
# plt.title("Poisson distribution")
# plt.xlabel("House Count")
# plt.ylabel("Room Count")
# plt.show()

# # Î» â€” Poisson paylanmasÄ±nÄ±n orta dÉ™yÉ™ri (mean)

# # ------------------------------
# #        NORMAL TEST NÃœMUNÆSÄ°
# # ------------------------------

# normal_data = np.random.normal(loc=4, scale=1, size=1000)

# # stat, p_value = normaltest(normal_data)
# # print(stat, p_value)
# # if p_value > 0.05:
# #     print("Normal Distribution")
# # else:
# #     print("Not Normal Distribution")

# # ------------------------------
# #        POISSON TEST NÃœMUNÆSÄ°
# # ------------------------------

# poisson_data = np.random.poisson(2, size=1000)

# # observed_count = np.bincount(poisson_data)
# # expected_count = [poisson.pmf(i, 2) * len(poisson_data) for i in range(len(observed_count))]
# # expected_count[-1] += len(poisson_data) - sum(expected_count)

# # chi_stat, p_value = chisquare(observed_count, expected_count)
# # print(chi_stat, p_value)

# # ------------------------------
# #        SKEWNESS
# # ------------------------------


# # ğŸ¯ Skew (Skewness) nÉ™dir?

# # Skewness â€” paylanmanÄ±n simmetrik olub-olmamasÄ±nÄ± gÃ¶stÉ™rÉ™n statistik Ã¶lÃ§Ã¼dÃ¼r.

# # SadÉ™ dildÉ™:

# # Paylanma saÄŸa É™yilirsÉ™ â†’ Ã§ox kiÃ§ik dÉ™yÉ™rlÉ™r var, az bÃ¶yÃ¼k â†’ skew > 0

# # Paylanma sola É™yilirsÉ™ â†’ Ã§ox bÃ¶yÃ¼k dÉ™yÉ™rlÉ™r var, az kiÃ§ik â†’ skew < 0

# # Paylanma tam simmetrikdirsÉ™ â†’ skew â‰ˆ 0

# print("Skewness with Normal data:", stats.skew(normal_data))
# print("Skewness with Poisson data:", stats.skew(poisson_data))
# print("Skewness with Excel houses data:", stats.skew(house_room_count))




# # print("Skewness with Possion data")
# # print(stats.skew(possion_data))




# # print("Skewness with Excel houses data")
# # print(stats.skew(house_room_count))

#endregion


#region PythonAi7

# # 1ï¸âƒ£ Regression nÉ™ Ã¼Ã§Ã¼n istifadÉ™ olunur?

# # MÉ™qsÉ™d: Bir vÉ™ ya bir neÃ§É™ mÃ¼stÉ™qil dÉ™yiÅŸÉ™n (X) É™sasÄ±nda bir asÄ±lÄ± dÉ™yiÅŸÉ™n (y) proqnoz etmÉ™k.

# # Misal:

# # Ev Ã¶lÃ§Ã¼sÃ¼ vÉ™ otaq sayÄ± â†’ evin qiymÉ™ti

# # Reklam xÉ™rclÉ™ri â†’ satÄ±ÅŸ sayÄ±

# # Temperatur vÉ™ rÃ¼tubÉ™t â†’ enerji sÉ™rfiyyatÄ±

# # 2ï¸âƒ£ Regression nÃ¶vlÉ™ri

# # Linear Regression (XÉ™tti Regression): y = a*X + b
# # Æn sadÉ™ formadÄ±r, nÉ™ticÉ™ mÃ¼stÉ™qil dÉ™yiÅŸÉ™nlÉ™rlÉ™ xÉ™tti É™laqÉ™dÉ™dir.

# # Polynomial Regression (Polinomial Regression): y = a*X^2 + b*X + c
# # X vÉ™ y arasÄ±nda xÉ™tti olmayan É™laqÉ™lÉ™r Ã¼Ã§Ã¼n.

# # Multiple Regression (Ã‡oxlu Regression): Bir neÃ§É™ X istifadÉ™ olunur: y = a1*X1 + a2*X2 + ... + b

# # DigÉ™r nÃ¶vlÉ™r: Ridge, Lasso, Decision Tree Regression, Random Forest Regression vÉ™ s.


# # X â†’ mÃ¼stÉ™qil dÉ™yiÅŸÉ™n (input, predictor)

# # y â†’ asÄ±lÄ± dÉ™yiÅŸÉ™n (output, target)

# # a â†’ meyl (slope) â€“ X dÉ™yiÅŸdikcÉ™ y nÉ™ qÉ™dÉ™r dÉ™yiÅŸir

# # b â†’ intercept (kÉ™silmÉ™ nÃ¶qtÉ™si) â€“ X=0 olanda y-nin qiymÉ™ti



# #MAE- Mean Absolute Error-ortalama sehv
# #y=[100,110,120]
# #y^=[103,113,124]
# #MAE=(|103-100|+|113-110|+|124-100|)/3=3.3


# # MSE â€” Mean Squared Error, yÉ™ni Ortalama Kvadrat SÉ™hv demÉ™k

# #y=[100,110,120]
# #y^=[103,113,124]
# #MSE=(|103-100|^2+|113-110|^2+|124-100|^2)/3=3.3/34......

# #R2=1-(3.3/34)=90%  RÂ² Score Modelin nÉ™ qÉ™dÉ™r dÃ¼zgÃ¼n proqnoz etdiyini gÃ¶stÉ™rir (0â€“1 arasÄ±)

# # Regression Metrics




# import numpy as np
# import matplotlib.pyplot as plt
# import pandas as pd





# # â€œpltâ€ â€” Python-da matplotlib.pyplot modulunun qÄ±saldÄ±lmÄ±ÅŸ adÄ±dÄ±r.

# # SÉ™n kodda bunu gÃ¶rmÃ¼sÉ™n:

# # import matplotlib.pyplot as plt


# # Bu sÉ™tr matplotlib.pyplot kitabxanasÄ±nÄ± plt adÄ± ilÉ™ Ã§aÄŸÄ±rmaÄŸa imkan verir.

# # ğŸ¯ plt nÉ™ Ã¼Ã§Ã¼ndÃ¼r?

# # plt istifadÉ™ olunur:

# # qrafik Ã§É™kmÉ™k

# # histogram yaratmaq

# # scatter plot Ã§É™kmÉ™k

# # x/y oxlarÄ±nÄ± yazmaq

# # baÅŸlÄ±q É™lavÉ™ etmÉ™k

# # qrafiki gÃ¶stÉ™rmÉ™k

# # yÉ™ni bÃ¼tÃ¼n vizualizasiya (qrafik) É™mÉ™liyyatlarÄ±nda.



# from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score

# # mae=mean_absolute_error(price,pred)
# # mse=mean_squared_error(price,pred)

# # print(mae)
# # print(mse)
# # r2=r2_score(price,pred)



# # while True:
# #     area=int(input("Enter the area of interest: "))
# #     Pred=a*area+b
# #     print(Pred)




# # ÆlbÉ™ttÉ™! GÉ™lin kovariyant (covariance) anlayÄ±ÅŸÄ±nÄ± tam sadÉ™ ÅŸÉ™kildÉ™ izah edÉ™k.

# # 1ï¸âƒ£ Kovariyant nÉ™dir?

# # Kovariyant iki dÉ™yiÅŸÉ™nin birlikdÉ™ necÉ™ dÉ™yiÅŸdiyini gÃ¶stÉ™rÉ™n Ã¶lÃ§Ã¼dÃ¼r.

# # Ä°ki dÉ™yiÅŸÉ™n eyni istiqamÉ™tdÉ™ dÉ™yiÅŸirsÉ™ â†’ kovariyant mÃ¼sbÉ™t olur.

# # Ä°ki dÉ™yiÅŸÉ™n É™ks istiqamÉ™tdÉ™ dÉ™yiÅŸirsÉ™ â†’ kovariyant mÉ™nfi olur.

# # HeÃ§ bir É™laqÉ™si yoxdursa â†’ kovariyant 0-a yaxÄ±n olur.


# # 2) Dispersiya(variance) nÉ™dir?

# # Dispersiya bir dÉ™yiÅŸÉ™nin orta dÉ™yÉ™rdÉ™n nÉ™ qÉ™dÉ™r uzaqlaÅŸdÄ±ÄŸÄ±nÄ± Ã¶lÃ§Ã¼r.
# # SadÉ™ desÉ™k, bir sÄ±ra dÉ™yÉ™rlÉ™rin nÉ™ qÉ™dÉ™r â€œyayÄ±lmÄ±ÅŸâ€ olduÄŸunu gÃ¶stÉ™rir.


# ğŸ”¹ Dispersiya (Variance) nÉ™dir?
# DÉ™yÉ™rlÉ™rin orta qiymÉ™tdÉ™n neÃ§É™ vahidÂ² uzaqlaÅŸdÄ±ÄŸÄ±nÄ± Ã¶lÃ§É™n gÃ¶stÉ™ricidir.
# YÉ™ni orta kvadratik kÉ™narlaÅŸmadÄ±r.


# Std (Standard Deviation) nÉ™dir?

# DispersiyanÄ±n kvadrat kÃ¶kÃ¼ demÉ™kdir.


# #Gradient Descent


# # Gradient Descent â€” Machine Learning modelinin â€œdaha yaxÅŸÄ± cavabâ€ tapmaq Ã¼Ã§Ã¼n tÉ™krarlayaraq Ã¶zÃ¼nÃ¼ dÃ¼zÉ™ltmÉ™ metodudur.

# # Model sÉ™hv edir â†’ sÉ™hvin Ã¶lÃ§Ã¼sÃ¼ hesablanÄ±r â†’ model sÉ™hvi azaltmaq Ã¼Ã§Ã¼n kiÃ§ik addÄ±m dÉ™yiÅŸiklik edir â†’ yenidÉ™n yoxlanÄ±r.


# # Æla, sÉ™n sadÉ™ bir Linear Regression (XÉ™tti reqressiya) modelini gradient descent ilÉ™ sÄ±fÄ±rdan yazmÄ±san

# # X=area
# # Y=price


# # m=1300
# # b=80000
# # Y_pred=m*X+b
# # print(Y_pred)
# # L=0.0001    #learning rate
# # epochs=40000


# # n=len(X)
# # for i in range(epochs):
# #    Y_pred=m*X+b
# #    D_m=(-2/n)*sum(X*(Y-Y_pred))
# #    D_b=(-2/n)*sum(Y-Y_pred)
# #    m=m-L*D_m
# #    b=b-L*D_b


# # print(m)
# # print(b)


# # mae=mean_absolute_error(Y,Y_pred)
# # mse=mean_squared_error(Y,Y_pred)
# # print("================")
# # print(mae)
# # print(mse)
# # r2=r2_score(Y,Y_pred)
# # print(r2)





# # VerilÉ™nlÉ™r (X = sahÉ™, Y = qiymÉ™t)
# area = np.array([50, 55, 60, 65, 70, 80, 90, 100, 120])
# price = np.array([150000, 165000, 180000, 195000, 210000, 220000, 230000, 240000, 280000])

# # BaÅŸlanÄŸÄ±c dÉ™yÉ™rlÉ™r (tÉ™sadÃ¼fi seÃ§ilmiÅŸ É™msallar)
# m = 1300     # xÉ™ttin meyli (slope)
# b = 80000    # y-kÉ™siÅŸmÉ™ nÃ¶qtÉ™si (intercept)

# # Proqnoz (Y_pred = tÉ™xmin edilÉ™n qiymÉ™tlÉ™r)
# Y_pred = m * area + b
# print(Y_pred)   # ilkin proqnozlar

# # HyperparametrlÉ™r
# L = 0.0001      # learning rate (Ã¶yrÉ™nmÉ™ sÃ¼rÉ™ti)
# epochs = 40000  # tÉ™krarlama sayÄ±
# n = len(area)   # nÃ¼munÉ™lÉ™rin sayÄ±

# # Gradient descent dÃ¶vrÃ¼
# for i in range(epochs):
#     # MÃ¶vcud modelÉ™ gÃ¶rÉ™ proqnoz
#     Y_pred = m * area + b

#     # GradientlÉ™rin hesablanmasÄ±
#     # D_m vÉ™ D_b - xÉ™ta funksiyasÄ±nÄ±n tÃ¶rÉ™mÉ™lÉ™ri (slope vÉ™ intercept Ã¼Ã§Ã¼n)
#     D_m = (-2/n) * sum(area * (price - Y_pred))  # m Ã¼zrÉ™ dÉ™yiÅŸmÉ™
#     D_b = (-2/n) * sum(price - Y_pred)           # b Ã¼zrÉ™ dÉ™yiÅŸmÉ™

#     # ÆmsallarÄ±n yenilÉ™nmÉ™si
#     m = m - L * D_m
#     b = b - L * D_b

# # NÉ™ticÉ™ É™msallar (m vÉ™ b)
# print("Ã–yrÉ™nilmiÅŸ m:", m)
# print("Ã–yrÉ™nilmiÅŸ b:", b)

# # Modelin keyfiyyÉ™t gÃ¶stÉ™ricilÉ™ri
# mae = mean_absolute_error(price, Y_pred)  # orta mÃ¼tlÉ™q xÉ™ta
# mse = mean_squared_error(price, Y_pred)   # orta kvadrat xÉ™ta
# r2 = r2_score(price, Y_pred)              # R^2 skor (modelin uyÄŸunluÄŸu)

# print("================")
# print("MAE:", mae)
# print("MSE:", mse)
# print("R2 Score:", r2)



# SadÉ™ Linear Regression Ã¼Ã§Ã¼n formulla (covariance ilÉ™) hesablamaq daha rahatdÄ±r.
# Amma Ã¶yrÉ™nmÉ™ vÉ™ machine learning Ã¼Ã§Ã¼n â€” Gradient Descent daha vacibdir vÉ™ daha gÃ¼clÃ¼ Ã¼suldur.

#endregion

#region PythonAi8

# import numpy as np
# import pandas as pd
# from sklearn.impute import SimpleImputer
# from sklearn.preprocessing import StandardScaler,OneHotEncoder


#region Uzun versiya 
# # ------------------------------
# # 1) MISSING VALUES (NaN) Ä°MPUTATION
# # ------------------------------

# # DataFrame yaradÄ±rÄ±q (bÉ™zilÉ™rindÉ™ NaN boÅŸ dÉ™yÉ™rlÉ™r var)
# data = {
#     'Rooms': [2, 3, np.nan, 4, 3],
#     'Area_m2': [60, 80, 100, np.nan, 120],
#     'Price_AZN': [90000, 120000, 150000, 200000, np.nan]
# }

# # Æsas DataFrame
# df = pd.DataFrame(data)

# # NaN dÉ™yÉ™rlÉ™r median ilÉ™ doldurulacaq
# # strategy='median' â†’ boÅŸ yerlÉ™ri median ilÉ™ É™vÉ™z edir
# imputer = SimpleImputer(strategy='median')

# print("---- ÆvvÉ™lki DataFrame ----")
# print(df)

# # fit_transform() â†’ hÉ™m Ã¶yrÉ™nir, hÉ™m doldurur
# df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)

# print("\n---- NaN-lar doldurulmuÅŸ DataFrame ----")
# print(df_imputed)



# # ------------------------------
# # 2) ONE-HOT ENCODING (Kategoriya -> SayÄ± formatÄ±)
# # ------------------------------

# # Rayon adlarÄ± (kategoriya mÉ™lumatÄ±)
# df = pd.DataFrame({
#     'District': ['Yasamal', 'Nizami', 'Sebayil', 'Yasamal', 'Sebayil']
# })

# # OneHotEncoder â†’ hÉ™r rayon Ã¼Ã§Ã¼n ayrÄ±ca sÃ¼tun yaradÄ±r (0 vÉ™ 1)
# encoder = OneHotEncoder(sparse_output=False)

# # fit_transform() â†’ hÉ™m Ã¶yrÉ™nir, hÉ™m Ã§evrilir
# encoded = encoder.fit_transform(df[['District']])

# # Yeni sÃ¼tun adlarÄ±nÄ± alÄ±rÄ±q
# encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(['District']))

# print("\n---- One-Hot Encoding nÉ™ticÉ™si ----")
# print(encoded_df)


# from sklearn.preprocessing import StandardScaler

# X=pd.DataFrame({
#     'Area_m2':[50,70,100,150,200],
#     'Rooms':[1,2,3,4,5]
# })

# scaler = StandardScaler()
# scaled=scaler.fit_transform(X)
# scaled_df = pd.DataFrame(scaled,columns=X.columns)
# print(scaled_df)



#scaling prfonrmansin artmasi ve hesablamanin balansi olmasi ucundue?


# Scaling modelin rÉ™qÉ™mlÉ™ri daha yaxÅŸÄ± baÅŸa dÃ¼ÅŸmÉ™si, daha tez Ã¶yrÉ™nmÉ™si vÉ™ daha dÃ¼zgÃ¼n nÉ™ticÉ™ vermÉ™si Ã¼Ã§Ã¼ndÃ¼r.




# ğŸ”µ Multiple Linear Regression nÉ™dir?

# Bu, birdÉ™n Ã§ox dÉ™yiÅŸÉ™n istifadÉ™ edÉ™rÉ™k bir nÉ™ticÉ™ni proqnoz edÉ™n modeldir.

# y^â€‹=b+a1â€‹x1â€‹+a2â€‹x2â€‹+...+anâ€‹xnâ€‹


# ğŸ”µ Multiple Linear Regression ML-in hansÄ± hissÉ™sinÉ™ daxildir?
# âœ” Machine Learning â†’ Supervised Learning â†’ Regression

# Bu ardÄ±cÄ±llÄ±qla gedir:

# Machine Learning (Ãœmumi sahÉ™)

# Supervised Learning (NÉ™zarÉ™t olunan Ã¶yrÉ™nmÉ™ â€” modelÉ™ hÉ™m input, hÉ™m dÉ™ cavab verilir)

# Regression (NÉ™ticÉ™ rÉ™qÉ™m olanda)

# Linear Regression

# Multiple Linear Regression

# YÉ™ni struktur belÉ™dir:

# Machine Learning
#  â””â”€â”€ Supervised Learning
#       â””â”€â”€ Regression
#            â””â”€â”€ Linear Regression
#                 â””â”€â”€ Multiple Linear Regression

# ğŸ”µ NiyÉ™ ML sayÄ±lÄ±r?

# Ã‡Ã¼nki:

# Model mÉ™lumatdan Ã¶yrÉ™nir

# Ã–yrÉ™nilÉ™n É™msallarla (aâ‚, aâ‚‚, aâ‚ƒ...) proqnoz edir

# XÉ™ta azaldÄ±lÄ±r, model optimallaÅŸdÄ±rÄ±lÄ±r

# Yeni mÉ™lumat verÉ™ndÉ™ cavab tapÄ±r

# Bu klassik ML davranÄ±ÅŸÄ±dÄ±r.


# import random

# np.random.seed(42)
# districts = ["Yasamal", "Nizami", "Sabayil", "Khatai", "Binagadi", "Narimanov"]
# building_types = ["New", "Old", "Premium", "Economy"]

# data = {
#     "Rooms": np.random.randint(1, 6, 100),
#     "Area_m2": np.random.randint(40, 250, 100),
#     "District": [random.choice(districts) for _ in range(100)],
#     "BuildingType": [random.choice(building_types) for _ in range(100)],
#     "Floor": np.random.choice([1, 2, 3, 4, 5, np.nan], 100, p=[0.15,0.15,0.2,0.2,0.2,0.1]),
#     "YearBuilt": np.random.choice([2000, 2005, 2010, 2015, 2020, np.nan], 100, p=[0.15,0.15,0.2,0.2,0.2,0.1]),
# }

# price = (
#     data["Area_m2"] * 1000
#     + data["Rooms"] * 8000
#     + np.random.randint(-30000, 30000, 100)
# )
# data["Price_AZN"] = price

# df = pd.DataFrame(data)
# df.to_excel("houses_extended.xlsx", index=False)


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler,OneHotEncoder
from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score
from sklearn.impute import SimpleImputer



df=pd.read_excel("houses_extended.xlsx")
#print(df.head())
#print(df.info())



# X â†’ modelin istifadÉ™ edÉ™cÉ™yi input mÉ™lumatlar (Price_AZN sÃ¼tunu Ã§Ä±xÄ±lÄ±b)
X = df.drop("Price_AZN", axis=1)

# y â†’ modelin proqnoz etmÉ™li olduÄŸu nÉ™ticÉ™ (Price_AZN)
y = df["Price_AZN"]

# RÉ™qÉ™mli (numeric) sÃ¼tunlarÄ±n siyahÄ±sÄ±
num_cols = ["Rooms", "Area_m2", "Floor", "YearBuilt"]

# Kategorik (categorical) sÃ¼tunlarÄ±n siyahÄ±sÄ±
cat_cols = ["District", "BuildingType"]

# ==========================================
# RÉ™qÉ™mli mÉ™lumatlar Ã¼Ã§Ã¼n pipeline
# 1) NaN-larÄ± median ilÉ™ doldurur
# 2) RÉ™qÉ™mlÉ™ri StandardScaler ilÉ™ standartlaÅŸdÄ±rÄ±r
numeric_transformer = Pipeline(steps=[
   ('imputer', SimpleImputer(strategy='median')),
   ('scaler', StandardScaler())
])

# ==========================================
# Kategorik mÉ™lumatlar Ã¼Ã§Ã¼n pipeline
# 1) NaN-larÄ± É™n Ã§ox tÉ™krarlanan dÉ™yÉ™rlÉ™ doldurur
# 2) One-hot encoding ilÉ™ hÉ™r kateqoriyanÄ± sÃ¼tuna Ã§evirir
#    handle_unknown='ignore' â†’ train-dÉ™ olmayan dÉ™yÉ™rlÉ™r gÉ™lsÉ™ xÉ™taya dÃ¼ÅŸmÉ™sin
categorical_transformer = Pipeline(steps=[
   ('imputer', SimpleImputer(strategy='most_frequent')),
   ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

# ==========================================
# ColumnTransformer ilÉ™ bÃ¼tÃ¼n mÉ™lumatlarÄ± birlÉ™ÅŸdiririk
# - RÉ™qÉ™mli sÃ¼tunlara numeric_transformer tÉ™tbiq olunur
# - Kategorik sÃ¼tunlara categorical_transformer tÉ™tbiq olunur
preprocessor = ColumnTransformer(
   transformers=[
       ('num', numeric_transformer, num_cols),
       ('cat', categorical_transformer, cat_cols),
   ]
)

# ==========================================
# 1ï¸âƒ£ Pipeline ilÉ™ model yaratmaq
# 'preprocessor' â†’ ColumnTransformer-i tÉ™tbiq edir (numeric + categorical preprocessing)
# 'regressor'   â†’ Linear Regression modelini É™lavÉ™ edir
model = Pipeline(steps=[
   ('preprocessor', preprocessor),
   ('regressor', LinearRegression())
])

# ==========================================
# 2ï¸âƒ£ Train vÉ™ test set-lÉ™rÉ™ bÃ¶lmÉ™k
# X_train, y_train â†’ modelin Ã¶yrÉ™nÉ™cÉ™yi mÉ™lumatlar (training data)
# X_test, y_test   â†’ modelin performansÄ±nÄ± yoxlayacaÄŸÄ± mÉ™lumatlar (test data)
# test_size=0.2    â†’ verilÉ™nlÉ™rin 20%-i test Ã¼Ã§Ã¼n, 80%-i train Ã¼Ã§Ã¼n ayrÄ±lÄ±r
# random_state=42  â†’ nÉ™ticÉ™lÉ™rin tÉ™krar eyni olmasÄ± Ã¼Ã§Ã¼n seed tÉ™yin olunur
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

model.fit(X_train, y_train)


pred=model.predict(X_test)  #random secilmis 20 % gore hesablanir.


mae=mean_absolute_error(y_test,pred)
mse=mean_squared_error(y_test,pred)
r2=r2_score(y_test,pred)
print(mae)
print(mse)
print(r2)



# encoder = model.named_steps["preprocessor"].named_transformers_["cat"].named_steps["encoder"]
# encoded_feature_names = encoder.get_feature_names_out(cat_cols)
#
# feature_names = num_cols + list(encoded_feature_names)
#
# coef = model.named_steps["regressor"].coef_
# importance = pd.Series(coef, index=feature_names).sort_values(ascending=False)
#
# print("\nÆn Ã§ox tÉ™sir edÉ™n sÃ¼tunlar:\n")
# print(importance.head(10))
#endregion



#region Qisa versiya

# 1ï¸âƒ£ Dataset vÉ™ target

# Input features (X) â†’ Rooms, Area_m2, Floor, YearBuilt, District, BuildingType

# Target (y) â†’ Price_AZN (proqnoz etmÉ™k istÉ™diyimiz qiymÉ™t)

# 2ï¸âƒ£ Feature nÃ¶vlÉ™ri

# Numeric (rÉ™qÉ™mli) â†’ Rooms, Area_m2, Floor, YearBuilt

# Categorical (kateqorik) â†’ District, BuildingType

# 3ï¸âƒ£ Data preprocessing (Ã¶n emal)

# Numeric pipeline:

# SimpleImputer(strategy='median') â†’ NaN-larÄ± median ilÉ™ doldurur

# StandardScaler() â†’ bÃ¼tÃ¼n rÉ™qÉ™mlÉ™ri standartlaÅŸdÄ±rÄ±r (mean=0, std=1)

# Categorical pipeline:

# SimpleImputer(strategy='most_frequent') â†’ NaN-larÄ± É™n Ã§ox tÉ™krarlanan dÉ™yÉ™rlÉ™ doldurur

# OneHotEncoder(handle_unknown='ignore') â†’ hÉ™r kateqoriyanÄ± 0/1 sÃ¼tunlarÄ±na Ã§evirir

# BÃ¼tÃ¼n sÃ¼tunlarÄ± birlÉ™ÅŸdirir: ColumnTransformer

# 4ï¸âƒ£ Model

# Linear Regression â†’ bir neÃ§É™ input feature-dan price-i proqnoz edir

# Pipeline-da hÉ™m preprocessing, hÉ™m model bir yerdÉ™dir

# 5ï¸âƒ£ Train/Test split

# train_test_split(test_size=0.2) â†’ 80% train, 20% test

# Random state 42 â†’ nÉ™ticÉ™ tÉ™krar olunur

# 6ï¸âƒ£ Model Ã¶yrÉ™dilmÉ™si
# model.fit(X_train, y_train)


# Pipeline avtomatik olaraq:

# Numeric vÉ™ categorical preprocessing edir

# Linear Regression-i Ã¶yrÉ™dir

# 7ï¸âƒ£ Performance Ã¶lÃ§Ã¼lÉ™ri

# MAE â†’ orta abs(xÉ™ta)

# MSE â†’ orta kvadrat xÉ™tasÄ±

# RÂ² â†’ modelin izahat gÃ¼cÃ¼ (1.0 yaxÅŸÄ±, 0.0 pis)

# mae=mean_absolute_error(y_test,pred)
# mse=mean_squared_error(y_test,pred)
# r2=r2_score(y_test,pred)

# 8ï¸âƒ£ Yeni mÉ™lumatdan proqnoz

# Ä°stifadÉ™Ã§i input verir: Rooms, Area_m2, District, BuildingType, Floor, YearBuilt

# Yeni DataFrame yaradÄ±lÄ±r â†’ model.predict(new_df) ilÉ™ price tÉ™xmin olunur

# 9ï¸âƒ£ NÉ™ticÉ™

# Pipeline + Linear Regression â†’ tam ML workflow

# Kod bÃ¼tÃ¼n preprocessing-i avtomatik edir â†’ NaN-larÄ± doldurur, scale edir, one-hot encoding tÉ™tbiq edir

# Model tÉ™lim olunub â†’ yeni input Ã¼Ã§Ã¼n qiymÉ™t tÉ™xmin edir


# StandartScaler rÉ™qÉ™mli sÃ¼tunlarÄ± 0 ortalama, 1 standart sapma ilÉ™ normalizÉ™ edir ki, model tez, stabil vÉ™ balanslÄ± Ã¶yrÉ™nsin.

 

# | Funksiya          | NÉ™ edir                                   |
# | ----------------- | ----------------------------------------- |
# | `fit()`           | ParametrlÉ™ri Ã¶yrÉ™nir                      |
# | `transform()`     | MÉ™lumatÄ± Ã¶yrÉ™nilmiÅŸ parametrlÉ™rlÉ™ Ã§evirir |
# | `fit_transform()` | HÉ™m Ã¶yrÉ™nir, hÉ™m Ã§evirir                  |



#endregion




#endregion 



#region PythonAi9
# 1)B+
# 2)B+
# 3)C+
# 4)B+
# 5)A+
# 6)A+
# 7)B+
# 8)B+
# 9)B+
# 10)A+
# 11)D- CAVAB B-DIR.
# 12)B+
# 13)A+
# 14)A+
# 15)B+
# 16)A+
# 17)A+
# 18)A+
# 19)C+
# 20)A+


# Lesson 9 cavablari ve imtahan ucun bir daha bax.Ve hemcinin aciq suallara da bax.

#endregion



#region PythonAi10

#  Polynominal and L1 L2 



# Overfitting â€” Machine Learning modelinin tÉ™lim (training) mÉ™lumatÄ±nÄ± hÉ™ddindÉ™n artÄ±q É™zbÉ™rlÉ™mÉ™si demÉ™kdir.
#  Model verilÉ™nlÉ™ri real nÃ¼munÉ™ kimi yox, sanki yaddaÅŸ kimi saxlayÄ±r

# NÉ™ticÉ™dÉ™:

# Training-dÉ™ Ã§ox yaxÅŸÄ± nÉ™ticÉ™ verir

# Test (real) mÉ™lumatlarda isÉ™ pis iÅŸlÉ™yir

# YÉ™ni model Ã¼mumilÉ™ÅŸdirÉ™ bilmir, sadÉ™cÉ™ yadda saxlayÄ±r.



# Underfitting â€” modelin hÉ™m training, hÉ™m dÉ™ test mÉ™lumatlarÄ±nda pis nÉ™ticÉ™ vermÉ™sidir.

# YÉ™ni model Ã§ox sadÉ™dir, mÉ™lumatÄ±n iÃ§indÉ™ki É™laqÉ™lÉ™ri Ã¶yrÉ™nÉ™ bilmir.





# Burada sklearn 5 testdÉ™n 5 nÉ™ticÉ™ Ã§Ä±xarÄ±r.

# scores = cross_val_score(...) â†’ bu cross validation scores demÉ™kdir.

# YÉ™ni:

# âœ”ï¸ Cross-validation = modeli bir neÃ§É™ dÉ™fÉ™ (mÉ™s: 5 dÉ™fÉ™) fÉ™rqli hissÉ™lÉ™rdÉ™ test etmÉ™k





# Polynomial Regression

# Polynomial Regression â€” linear regression-in bir variantÄ±dÄ±r, amma dÃ¼z xÉ™tt É™vÉ™zinÉ™ É™yri xÉ™tt Ã§É™kmÉ™yÉ™ imkan verÉ™n regresiya Ã¼suludur.

# y=a+bx+cx^2

# y â†’ Modelin proqnoz etdiyi nÉ™ticÉ™ (dependent variable).

# a â†’ Intercept (sabit termin). YÉ™ni x=0 olarkÉ™n y-nin dÉ™yÉ™ri.

# b â†’ x-in Ã§É™kisi (weight). Bu xÉ™tti termin Ã¼Ã§Ã¼n É™hÉ™miyyÉ™tini gÃ¶stÉ™rir.

# c â†’ xÂ²-in Ã§É™kisi (weight). Bu kvadratik termin Ã¼Ã§Ã¼n É™hÉ™miyyÉ™tini gÃ¶stÉ™rir.

# x â†’ MÃ¼stÉ™qil dÉ™yiÅŸÉ™n (feature).



#L1-Lasso
#L2-Ridge

#Regualization-

# Lasso (L1): Az tÉ™sir gÃ¶stÉ™rÉ™n (Ã¶nÉ™msiz) feature-lÉ™ri tam sÄ±fÄ±ra Ã§evirir, yÉ™ni onlarÄ± modeldÉ™n Ã§Ä±xarÄ±r.

# Ridge (L2): Ã‡ox tÉ™sir gÃ¶stÉ™rÉ™n (Ã¶nÉ™mli) feature-lÉ™rin Ã§É™kilÉ™rini azaldÄ±r, amma heÃ§ birini sÄ±fÄ±ra Ã§evirmir.



#endregion



#region PythonAi11

#Decision Tree and Rf

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score
from sklearn.model_selection import train_test_split


# https://medium.com/@shrutimisra/interpretable-ai-decision-trees-f9698e94ef9b (decision treenin sekli)



# # Decision Tree TerminlÉ™ri

# # 1)Root Node (KÃ¶k DÃ¼yÃ¼n)

# # AÄŸacÄ±n baÅŸlanÄŸÄ±c nÃ¶qtÉ™si

# # BÃ¼tÃ¼n mÉ™lumatlar buradan bÃ¶lÃ¼nmÉ™yÉ™ baÅŸlayÄ±r

# # MÉ™sÉ™lÉ™n: â€œRÉ™ngi qÄ±rmÄ±zÄ±dÄ±r?â€ sualÄ± root node ola bilÉ™r



# # 2)Decision Node (QÉ™rar DÃ¼yÃ¼nÃ¼ / Daxili DÃ¼yÃ¼n)

# # KÃ¶kdÉ™n sonra gÉ™lÉ™n vÉ™ mÉ™lumatÄ± bÃ¶lÉ™n dÃ¼yÃ¼nlÉ™r

# # HÉ™r bir dÃ¼yÃ¼n mÃ¼É™yyÉ™n xÃ¼susiyyÉ™tÉ™ gÃ¶rÉ™ qruplar yaradÄ±r

# # MÉ™sÉ™lÉ™n: â€œYumÅŸaqdÄ±r?â€ sualÄ± decision node ola bilÉ™r

# # Leaf Node (Yarpaqlar / Son DÃ¼yÃ¼n)

# # AÄŸacÄ±n nÉ™ticÉ™ verdiyi dÃ¼yÃ¼nlÉ™r




# # 3) Leaf node-da artÄ±q proqnoz vÉ™ ya nÉ™ticÉ™ var, yeni qÉ™rar verilmir

# # MÉ™sÉ™lÉ™n: â€œAlmaâ€, â€œBananâ€, â€œKiviâ€ leaf node-dur



# # 4)Subtree (Alt AÄŸac)

# # Decision node-dan baÅŸlayan vÉ™ leaf node ilÉ™ bitÉ™n aÄŸacÄ±n kiÃ§ik hissÉ™si

# # HÉ™r decision node Ã¶z subtree-inÉ™ malikdir

# # BaÅŸqa sÃ¶zlÉ™, subtree aÄŸacÄ±n bir kiÃ§ik hissÉ™si, Ã¶zÃ¼ dÉ™ kiÃ§ik bir aÄŸacdÄ±r

#yÉ™ni decison node+leaf node=subtree

# # 5)Entropy (Entropiya)

# # Dataset-dÉ™ki qarÄ±ÅŸÄ±qlÄ±q vÉ™ qeyri-mÃ¼É™yyÉ™nlik sÉ™viyyÉ™sini Ã¶lÃ§É™n gÃ¶stÉ™rici

# # Dataset tam qarÄ±ÅŸÄ±qdÄ±rsa â†’ entropy yÃ¼ksÉ™k

# # Dataset tam tÉ™mizdirsÉ™ â†’ entropy = 0


   # SadÉ™ dillÉ™ desÉ™k, qarÄ±ÅŸÄ±qlÄ±q dedikdÉ™ â€œdatasetdÉ™ki nÃ¼munÉ™lÉ™rin mÃ¼xtÉ™lif siniflÉ™rÉ™ (labels) necÉ™ paylandÄ±ÄŸÄ±â€ nÉ™zÉ™rdÉ™ tutulur.

   # ÆgÉ™r bÃ¼tÃ¼n nÃ¼munÉ™lÉ™r eyni sinifdÉ™dirsÉ™ â†’ qarÄ±ÅŸÄ±qlÄ±q yoxdur.

   # ÆgÉ™r nÃ¼munÉ™lÉ™r fÉ™rqli siniflÉ™r Ã¼zrÉ™ bÉ™rabÉ™r paylanÄ±bsa â†’ qarÄ±ÅŸÄ±qlÄ±q yÃ¼ksÉ™kdir.


# # 6)Information Gain (MÉ™lumat QazancÄ± / IG)


# Information Gain = bir feature istifadÉ™ edÉ™rÉ™k mÉ™lumatdakÄ± qeyri-mÃ¼É™yyÉ™nliyi nÉ™ qÉ™dÉ™r azalda bilÉ™rik.

# # IG=Entropy(S)âˆ’Weighted Entropy of subgroup

# # IG=0.881âˆ’0.583â‰ˆ0.29


# # âœ… NÉ™ticÉ™: Decision Tree tÉ™tbiqindÉ™n sonra qarÄ±ÅŸÄ±qlÄ±q azaldÄ±

# # BaÅŸlanÄŸÄ±c qarÄ±ÅŸÄ±qlÄ±q = 0.881

# # BÃ¶lmÉ™dÉ™n sonra = 0.583

# # FÉ™rq = 0.298 â†’ bu bÃ¶lmÉ™ ilÉ™ mÉ™lumat daha â€œtÉ™mizâ€ oldu

# # 4ï¸âƒ£ SadÉ™ desÉ™k

# # BaÅŸlanÄŸÄ±c qarÄ±ÅŸÄ±qlÄ±q: dataset qarÄ±ÅŸÄ±qdÄ±r, proqnoz qeyri-mÃ¼É™yyÉ™ndir

# # Decision Tree tÉ™tbiq etdikdÉ™n sonra: mÉ™lumat xÃ¼susiyyÉ™tlÉ™rÉ™ gÃ¶rÉ™ qruplara ayrÄ±lÄ±r, qarÄ±ÅŸÄ±qlÄ±q azalÄ±r, nÉ™ticÉ™lÉ™r daha dÉ™qiq olur



# # Decision Tree â€” verilÉ™nlÉ™ri xÃ¼susiyyÉ™tlÉ™rinÉ™ gÃ¶rÉ™ ardÄ±cÄ±l olaraq bÃ¶lÉ™n vÉ™ nÉ™ticÉ™dÉ™ qÉ™rar verÉ™n aÄŸac strukturu olan bir mÉ™ÅŸhur nÉ™zarÉ™tli Ã¶yrÉ™nmÉ™ (supervised learning) Ã¼suludur.



# #Random Forest Tree

# # Random Forest â€” Ã§oxlu Decision Tree-lÉ™rin (QÉ™rar AÄŸaclarÄ±) birlÉ™ÅŸmÉ™sidir.

# # TÉ™k aÄŸac = Decision Tree

# # Bir neÃ§É™ aÄŸacÄ±n birlikdÉ™ iÅŸlÉ™mÉ™si = Random Forest




# rf=RandomForestRegressor(
#     n_estimators=400,
#     max_depth=4,
#     min_samples_split=4,
#     n_jobs=-1,
#     random_state=42
# )

# # ğŸŒ² RandomForestRegressor ParametrlÉ™rinin TÆRÄ°FLÆRÄ°
# # 1ï¸âƒ£ n_estimators

# # TÉ™rif:
# # â¡ Random Forest-in iÃ§indÉ™ qurulacaq decision tree-lÉ™rin sayÄ±.

# # SÉ™nin dÉ™yÉ™rin: 400
# # YÉ™ni model 400 aÄŸac yaradacaq.

# # 2ï¸âƒ£ max_depth

# # TÉ™rif:
# # â¡ HÉ™r decision tree-nin icazÉ™ verilÉ™n maksimum dÉ™rinliyi (neÃ§É™ sÉ™viyyÉ™ enÉ™ bilÉ™cÉ™yi).

# # SÉ™nin dÉ™yÉ™rin: 4
# # YÉ™ni hÉ™r aÄŸac maksimum 4 sÉ™viyyÉ™ olacaq.

# # 3ï¸âƒ£ min_samples_split

# # TÉ™rif:
# # â¡ Bir node-un iki yerÉ™ bÃ¶lÃ¼nmÉ™si Ã¼Ã§Ã¼n minimum lazÄ±m olan sample sayÄ±.

# # SÉ™nin dÉ™yÉ™rin: 4
# # Node iÃ§indÉ™ 4-dÉ™n az sample varsa, bÃ¶lÃ¼nmÉ™yÉ™cÉ™k.

# # 4ï¸âƒ£ n_jobs

# # TÉ™rif:
# # â¡ Modelin train zamanÄ± istifadÉ™ edÉ™cÉ™yi CPU nÃ¼vÉ™lÉ™rinin sayÄ±.

# # SÉ™nin dÉ™yÉ™rin: -1
# # Bu demÉ™kdir: bÃ¼tÃ¼n CPU nÃ¼vÉ™lÉ™rini istifadÉ™ et â†’ maksimum sÃ¼rÉ™t.

# # 5ï¸âƒ£ random_state

# # TÉ™rif:
# # â¡ BÃ¼tÃ¼n random proseslÉ™ri (data seÃ§imi, feature seÃ§imi, split-lÉ™r) sabitlÉ™ÅŸdirÉ™n toxum (seed).

# # SÉ™nin dÉ™yÉ™rin: 42
# # YÉ™ni model hÉ™r dÉ™fÉ™ eyni nÉ™ticÉ™ni verÉ™cÉ™k.

# # âœ¨ QISA XÃœLASÆ
# # Parametr	TÉ™rif
# # n_estimators	AÄŸaclarÄ±n sayÄ±
# # max_depth	AÄŸacÄ±n maksimum dÉ™rinliyi
# # min_samples_split	Split Ã¼Ã§Ã¼n lazÄ±m olan minimum sample
# # n_jobs	CPU sayÄ± (paralellÉ™ÅŸmÉ™)
# # random_state	NÉ™ticÉ™ni sabit saxlamaq Ã¼Ã§Ã¼n random toxum



# # âœ” NÆTÄ°CÆ (super sadÉ™)

# # Random Forest = Ã§ox decision tree â†’ sÉ™hvlÉ™ri ortalaÅŸdÄ±rÄ±r â†’ daha gÃ¼clÃ¼ model yaradÄ±r.

# # Bu sÉ™bÉ™bdÉ™n istifadÉ™ edirik:

# # âœ“ daha stabil
# # âœ“ daha dÉ™qiq
# # âœ“ daha az overfitting
# # âœ“ daha etibarlÄ±
# # âœ“ daha gÃ¼clÃ¼ nÉ™ticÉ™











#endregion


#region PythonAi12


# GB EGB


# ğŸŒ² 1) Random Forest â€” paralel aÄŸaclar

# NÉ™dir?
# BirdÉ™n Ã§ox decision tree eyni anda (paralel) qurulur vÉ™ nÉ™ticÉ™lÉ™ri birlÉ™ÅŸdirilir.

# NiyÉ™ belÉ™ edir?
# Ã‡Ã¼nki Ã§ox aÄŸac birlikdÉ™ daha stabil nÉ™ticÉ™ verir.

# NecÉ™ iÅŸlÉ™yir?

# HÉ™r aÄŸac dataset-in bir hissÉ™sini gÃ¶rÃ¼r

# HÉ™r aÄŸac tÉ™sadÃ¼fi feature-lÉ™r seÃ§ir

# Sonda bÃ¼tÃ¼n aÄŸaclarÄ±n nÉ™ticÉ™lÉ™ri birlÉ™ÅŸdirilir (sÉ™svermÉ™ / orta)

# ğŸ‘‰ AÄŸaclar bir-birinin sÉ™hvini dÃ¼zÉ™ltmir.
# HamÄ±sÄ± eyni anda iÅŸlÉ™yir (paralel).

# ğŸ”¥ 2) Gradient Boosting â€” ardÄ±cÄ±l aÄŸaclar

# NÉ™dir?
# Decision tree-lÉ™r ardÄ±cÄ±l (sequence) qurulur vÉ™ sonrakÄ± aÄŸac É™vvÉ™lki aÄŸacÄ±n sÉ™hvlÉ™rini dÃ¼zÉ™ltmÉ™yÉ™ Ã§alÄ±ÅŸÄ±r.

# NecÉ™ iÅŸlÉ™yir?

# Ä°lk aÄŸac sadÉ™ proqnoz edir â†’ sÉ™hv edir

# Ä°kinci aÄŸac hÉ™min sÉ™hvlÉ™ri Ã¶yrÉ™nir vÉ™ dÃ¼zÉ™ltmÉ™yÉ™ Ã§alÄ±ÅŸÄ±r

# ÃœÃ§Ã¼ncÃ¼ aÄŸac É™vvÉ™lkilÉ™rin qalan sÉ™hvlÉ™rini dÃ¼zÉ™ldir

# BelÉ™-belÉ™ hÉ™r yeni aÄŸac daha dÉ™qiq olur

# ğŸ” YÉ™ni:
# tÉ™kmillÉ™ÅŸdirilÉ™n ardÄ±cÄ±l aÄŸaclar â†’ daha dÉ™qiq model

# âš¡ 3) XGBoost (Extreme Gradient Boosting)

# Gradient Boosting-in daha gÃ¼clÃ¼, daha sÃ¼rÉ™tli vÉ™ daha az overfitting edÉ™n versiyasÄ±dÄ±r.

# ÃœstÃ¼nlÃ¼klÉ™ri:

# regularization var

# daha sÃ¼rÉ™tli optimizasiya

# RAM istifadÉ™ Ã§ox effektli

# É™n Ã§ox Kaggle yarÄ±ÅŸmalarÄ±nÄ±n qalibi â†’ XGBoost






#endregion



#region PythonAi13



# ğŸš€ ANN nÉ™dir?
# ANN = Artificial Neural Network = SÃ¼ni Neyron ÅÉ™bÉ™kÉ™si
# Komputerin beyin kimi Ã¶yrÉ™nmÉ™ Ã¼suludur.

# ğŸ§  ANN necÉ™ iÅŸlÉ™yir?
# ANN mÉ™lumatÄ± Ã§oxlu kiÃ§ik neyronlar iÃ§indÉ™n keÃ§irÉ™rÉ™k nÉ™ticÉ™ Ã§Ä±xaran alqoritmdir.

# ğŸ”Œ ANN-in strukturu
# 1ï¸âƒ£ Input Layer â€” GiriÅŸ (mÉ™sÉ™lÉ™n, 13 xÃ¼susiyyÉ™t)
# 2ï¸âƒ£ Hidden Layer â€” Gizli qatlar (hesablama vÉ™ Ã¶yrÉ™nmÉ™ burada baÅŸ verir)
# 3ï¸âƒ£ Output Layer â€” Ã‡Ä±xÄ±ÅŸ (mÉ™sÉ™lÉ™n, 0 vÉ™ ya 1)


# ğŸ ANN-in istifadÉ™ sahÉ™lÉ™ri
# âœ” Ãœz tanÄ±ma
# âœ” SÉ™s tanÄ±ma
# âœ” ÅÉ™kil tÉ™snifatÄ±
# âœ” Proqnozlamalar
# âœ” Tibbi diaqnostika
# âœ” DÃ¶yÃ¼ÅŸ oyunlarÄ±nda botlar
# âœ” ChatGPT vÉ™ digÉ™r AI modellÉ™ri

# ğŸ“Š Regression vs Classification
# | XÃ¼susiyyÉ™t     | Regression                          | Classification                        |

# | Ã‡Ä±xÄ±ÅŸ tipi     | Real rÉ™qÉ™m (continuous)             | Sinif (categorical)                   |
# | Sual tipi      | NÉ™ qÉ™dÉ™r / neÃ§É™?                    | HansÄ±? HÉ™/Yox?                        |
# | NÃ¼munÉ™         | Ev qiymÉ™ti, maaÅŸ, temperatur        | XÉ™stÉ™/saÄŸlam, spam, piÅŸik/it          |
# | Ehtimal        | âŒ Yox                               | âœ… Ola bilÉ™r (sigmoid/softmax)         |
# | Model nÃ¼munÉ™si | Linear Regression, ANN (linear)    | Logistic Regression, ANN (sigmoid)   |

# ğŸŸ¢ Neyronun linear Ã§Ä±xÄ±ÅŸÄ± (1 neyron)
# DÃ¼stur: y = w1*x1 + w2*x2 + ... + wn*xn + b
# x â†’ giriÅŸ mÉ™lumatlarÄ± (features), misal: yaÅŸ, boy, Ã§É™ki
# w â†’ giriÅŸlÉ™rin Ã§É™kisi (weight), bÃ¶yÃ¼k Ã§É™kilÉ™r â†’ daha É™hÉ™miyyÉ™tli
# b â†’ bias (sabit dÉ™yÉ™r)

# Misal:
# x1 = 2, x2 = 3
# w1 = 0.5, w2 = 1.2
# b = 0.7
# y = 0.5*2 + 1.2*3 + 0.7 = 5.3

# ğŸŸ¢ Bias nÉ™dir?
# Bias = neyronun baÅŸlanÄŸÄ±c nÃ¶qtÉ™si, giriÅŸlÉ™r 0 olsa da Ã§Ä±xÄ±ÅŸ verÉ™ bilir
# Misal:
# x1 = 0, x2 = 0, w1 = 0.5, w2 = 1.2, b = 0.7 â†’ y = 0.7

# ğŸŸ¢ Input â†’ Weight â†’ Sum â†’ Activation â†’ Output
# - Input: x1, x2, ..., xn
# - Weight: w1, w2, ..., wn
# - Sum: Î£(wx) + b
# - Activation: Step / Sigmoid / ReLU
# - Output: Neyronun proqnozu (0/1 vÉ™ ya ehtimal)

# ğŸŸ¢ Perceptron
# - Æn sadÉ™ neyron modeli
# - Binary classification Ã¼Ã§Ã¼n
# - Aktivasiya funksiyasÄ±: Step (0/1)

# ğŸŸ¢ Multi-Layer Perceptron (MLP)
# - Ã‡ox qatlÄ± neyron ÅŸÉ™bÉ™kÉ™si
# - Input layer â†’ Hidden layers â†’ Output layer
# - Gizli qatlar mÃ¼rÉ™kkÉ™b patternlÉ™ri Ã¶yrÉ™nir
# - Aktivasiya funksiyasÄ±: ReLU, Sigmoid, Softmax
# - Binary vÉ™ Multi-class classification, regression Ã¼Ã§Ã¼n istifadÉ™ oluna bilÉ™r

# ğŸ”¹ Linear vs Non-linear
# - Linear neuron: y = w1*x1 + w2*x2 + ... + wn*xn + b â†’ dÃ¼z xÉ™tt
# - Non-linear neuron: y = activation(wx + b) â†’ parabola, sigmoid, softmax
# - Non-linear olmadan mÃ¼rÉ™kkÉ™b patternlÉ™r Ã¶yrÉ™nilÉ™ bilmÉ™z

# ğŸŸ¢ Qaydalar / É™sas anlayÄ±ÅŸlar
# 1. HÉ™r giriÅŸ Ã¶z Ã§É™kisi ilÉ™ vurulur, sonra hamÄ±sÄ± toplanÄ±r, bias É™lavÉ™ olunur.
# 2. Aktivasiya funksiyasÄ± linear Ã§Ä±xÄ±ÅŸÄ± ehtimala vÉ™ ya 0/1 kimi sÉ™rt Ã§Ä±xÄ±ÅŸa Ã§evirir.
# 3. Bias olmadan xÉ™tt hÉ™miÅŸÉ™ orijindÉ™n keÃ§ir, model mÉ™lumatÄ± yaxÅŸÄ± uyÄŸunlaÅŸdÄ±ra bilmir.
# 4. MLP-dÉ™ hidden qatlar modelin non-linear patternlÉ™ri Ã¶yrÉ™nmÉ™sini tÉ™min edir.
# 5. ANN-in Ã§Ä±xÄ±ÅŸÄ± problemi gÃ¶rÉ™ dÉ™yiÅŸir:
#    - Binary classification â†’ 0/1 vÉ™ ya 0â€“1 ehtimal
#    - Multi-class classification â†’ sinif indekslÉ™ri (0,1,2,...)
#    - Regression â†’ real dÉ™yÉ™r




# ğŸŸ¢ Perceptron vÉ™ Neyronun Ä°ÅŸlÉ™mÉ™ Mexanizmi

#meselen 13 neyron inputu varsa hiddenda 32 olmalidi

# Perceptron = É™n sadÉ™ neyron (Artificial Neuron) modelidir.

# x1 --- w1 \
# x2 --- w2  ---> Î£ (toplama) ---> Aktivasiya â†’ y (0/1)
# x3 --- w3 /
#           +
#           b (bias)

#Input=>Weight=>Sum=>Activation=>Output(1 neyronun isi)

#endregion

#region PythonAi14



#ilk 25 deq sual cavab

#PyTorch
# PyTorch Facebook (Meta) tÉ™rÉ™findÉ™n hazÄ±rlanmÄ±ÅŸ, aÃ§Ä±q-mÉ™nbÉ™ (open-source),
#  xÃ¼susilÉ™ dÉ™rin Ã¶yrÉ™nmÉ™ (deep learning) vÉ™ neyron ÅŸÉ™bÉ™kÉ™lÉ™ri
#  qurmaq Ã¼Ã§Ã¼n istifadÉ™ olunan Ã§ox gÃ¼clÃ¼ bir machine learning framework-dÃ¼r.





# Scalar -> 5
# Vector -> [2,3,4]
# Matrix -> [[1,2],[3,4]]
# Tensor -> [[[[1,1]],[2,2],[3,3]],[[4,4],[5,5],[6,6]],[[7,7]]]]


# | Ad     | Ã–lcÃ¼ | NÃ¼munÉ™                 |
# | ------ | ---- | ---------------------- |
# | Scalar | 0D   | `5`                    |
# | Vector | 1D   | `[2,3,4]`              |
# | Matrix | 2D   | `[[1,2],[3,4]]`        |
# | Tensor | 3D+  | `[[[[1,1]],[2,2]...]]` |

import torch
#
# #Scalar
a=torch.tensor(5)
#Vector
b=torch.tensor([1,2,3])
#Matrix
c=torch.tensor([[1,2],[3,4]])






#recordingin 1-ci hissesi 01.02.00


# 1ï¸âƒ£ Fully Connected Layer (nn.Linear)
#
# nn.Linear(in_features, out_features) â†’ hÉ™r bir giriÅŸ neyronu hÉ™r Ã§Ä±xÄ±ÅŸ neyronuna baÄŸlÄ±dÄ±r.
#
# Buna fully connected (tam baÄŸlÄ±) layer deyilir.

# fc1: 2 giriÅŸ neyronu â†’ 4 Ã§Ä±xÄ±ÅŸ neyronu
#
# HÉ™r 2 giriÅŸ hÉ™r 4 Ã§Ä±xÄ±ÅŸ neyronuna baÄŸlÄ±dÄ±r â†’ fully connected
#
# fc2: 4 giriÅŸ (hidden layer) â†’ 1 Ã§Ä±xÄ±ÅŸ
#
# HÉ™r 4 giriÅŸ Ã§Ä±xÄ±ÅŸ neyronuna baÄŸlÄ±dÄ±r â†’ fully connected


# Hidden layer inputdan bÃ¶yÃ¼k olmalÄ±dÄ±r?
#
# Xeyr, mÉ™cbur deyil.
#
# Amma input-dan bir az daha bÃ¶yÃ¼k seÃ§mÉ™k normaldÄ±r, ki model daha mÃ¼rÉ™kkÉ™b nÃ¼munÉ™lÉ™ri Ã¶yrÉ™nsin.



# 1ï¸âƒ£ Activation function nÉ™dir?
#
# Activation function (aktivasiya funksiyasÄ±) â†’ neyronun Ã§Ä±xÄ±ÅŸÄ±nÄ± mÃ¼É™yyÉ™n qaydada dÉ™yiÅŸdirÉ™n funksiyadÄ±r.
#
# Neyron ÅŸÉ™bÉ™kÉ™dÉ™ non-linearlÄ±q É™lavÉ™ etmÉ™k Ã¼Ã§Ã¼n istifadÉ™ olunur.
#


# | Funksiya | Ä°stifadÉ™                                                              |
# | -------- | --------------------------------------------------------------------- |
# | ReLU     | Hidden layer-lÉ™rdÉ™ (0-dan bÃ¶yÃ¼k dÉ™yÉ™rlÉ™ri saxlayÄ±r, mÉ™nfilÉ™ri 0 edir) |
# | Sigmoid  | Ã‡Ä±xÄ±ÅŸ layer-dÉ™, ehtimal Ã¼Ã§Ã¼n (0-1 aralÄ±ÄŸÄ±)                            |
# | Softmax  | Multi-class classification, ehtimallarÄ±n cÉ™mi 1 olur                  |


# 1ï¸âƒ£ Aktivasiya funksiyasÄ±nÄ±n yeri
#
# ANN (Artificial Neural Network)-dÉ™ aktivasiya funksiyasÄ± layer-lÉ™rin Ã§Ä±xÄ±ÅŸÄ±nda yerlÉ™ÅŸir.
#
# HÉ™r hidden layer-in sonunda
#
# Output layer-dÉ™n É™vvÉ™l (Ã§ox vaxt ehtimala Ã§evirmÉ™k Ã¼Ã§Ã¼n)







#endregion


#region PythonAi15


#ilk 23 deq sual cavab




# Activation funksiyalarÄ± neyron ÅŸÉ™bÉ™kÉ™lÉ™rindÉ™ neyronun Ã§Ä±xÄ±ÅŸÄ±nÄ± hesablamaq Ã¼Ã§Ã¼n istifadÉ™ olunur.(yeni cixisdan evvel hidden layerdan sonra )
# Onlar neyronun â€œaktiv olub-olmamasÄ±nÄ±â€ mÃ¼É™yyÉ™nlÉ™ÅŸdirir vÉ™ modelÉ™ xÉ™tti olmayanlÄ±q (non-linearity) É™lavÉ™ edir.
# ÆgÉ™r activation funksiyasÄ± olmasa, neyron ÅŸÉ™bÉ™kÉ™si yalnÄ±z xÉ™tti funksiyalarÄ± Ã¶yrÉ™nÉ™ bilÉ™r vÉ™ mÃ¼rÉ™kkÉ™b nÃ¼munÉ™lÉ™ri tanÄ±ya bilmÉ™z.




#her birini nezeri numune yaz............


# Sigmoid â€“ 0â€“1 arasÄ± ehtimal verir, adÉ™tÉ™n binary classification Ã¼Ã§Ã¼n.

# Softmax â€“ 0â€“1 arasÄ± ehtimal verir, multi-class classification Ã¼Ã§Ã¼n (siniflÉ™r Ã¼zrÉ™ cÉ™mi 1 olur).


# 1ï¸âƒ£ Sigmoid

# Ã‡Ä±xÄ±ÅŸ: 0 â€“ 1 arasÄ±

# Ä°stifadÉ™: Binary classification (ikili tÉ™snifat)

# Dezavantaj: Vanishing gradient problem (Ã§ox bÃ¶yÃ¼k vÉ™ ya kiÃ§ik x dÉ™yÉ™rlÉ™rindÉ™ gradient itir)



# 2ï¸âƒ£ ReLU (Rectified Linear Unit)

# Ã‡Ä±xÄ±ÅŸ: 0 â€“ âˆ

# MÉ™nfi dÉ™yÉ™rlÉ™ri 0 edir

# Ä°stifadÉ™: Hidden layer-lÉ™rdÉ™ Ã§ox istifadÉ™ olunur

# Dezavantaj: Dead neuron problem (bÉ™zÉ™n neyron tamamilÉ™ deaktiv ola bilÉ™r)


# 3ï¸âƒ£ Softmax

# Ã‡Ä±xÄ±ÅŸ: 0 â€“ 1 arasÄ±, cÉ™mi 1

# Ä°stifadÉ™: Multi-class classification (Ã§oxlu sinifli tÉ™snifat)

#Dezavantaj: Softmax Ã§oxlu siniflÉ™r Ã¼Ã§Ã¼n É™la ehtimal verir, amma Ã§ox bÃ¶yÃ¼k vÉ™ ya Ã§oxlu logit-lÉ™rdÉ™ hÉ™ssas vÉ™ aÄŸÄ±r ola bilÉ™r.




# ReLU: mÉ™nfilÉ™ri tam 0 edir

# Sigmoid: mÉ™nfilÉ™ri 0-a yaxÄ±n, amma sÄ±fÄ±r deyil edir


# Kodun izahÄ±



# ReLU â†’ hidden layer-lÉ™rdÉ™ istifadÉ™ olunur (mÉ™nfilÉ™ri 0 edir, non-linearity É™lavÉ™ edir)

# Sigmoid â†’ Ã§Ä±xÄ±ÅŸda ehtimal verir (0â€“1 arasÄ±), Ã§Ã¼nki xÉ™stÉ™liyin olub-olmamasÄ± binary



#endregion


#region PythonAi16




# CNN nÉ™dir? (Convolutional Neural Network)

# CNN â€“ Konvolyusion Neyron ÅÉ™bÉ™kÉ™si demÉ™kdir. Bu, ÅŸÉ™kil, video, obyekt tanÄ±ma, tÉ™snifat, Ã¼z tanÄ±ma kimi vizual mÉ™lumatlarla iÅŸlÉ™mÉ™k Ã¼Ã§Ã¼n yaradÄ±lmÄ±ÅŸ xÃ¼susi neyron ÅŸÉ™bÉ™kÉ™ nÃ¶vÃ¼dÃ¼r.




# CNN nÉ™ iÅŸ gÃ¶rÃ¼r?

# ÅÉ™killÉ™rdÉ™ xÃ¼susiyyÉ™tlÉ™ri (edges, rÉ™ng keÃ§idlÉ™ri, formalar) Ã¶zÃ¼ avtomatik tapÄ±r.

# Ä°nsan beyninin gÃ¶rmÉ™ sisteminÉ™ bÉ™nzÉ™yir â€” É™vvÉ™l xÄ±rda ÅŸeylÉ™ri tapÄ±r, sonra daha bÃ¶yÃ¼k strukturlarÄ± anlayÄ±r.






# NiyÉ™ adi neyron ÅŸÉ™bÉ™kÉ™dÉ™n fÉ™rqlidir?

# Adi ÅŸÉ™bÉ™kÉ™lÉ™r bÃ¼tÃ¼n piksellÉ™rÉ™ birdÉ™n baxÄ±r. CNN isÉ™ ÅŸÉ™kli kiÃ§ik hissÉ™lÉ™rÉ™ bÃ¶lÃ¼b filterlÉ™rlÉ™ (kernel) â€œsÃ¼zÃ¼râ€ vÉ™ maraqlÄ± nÃ¼munÉ™lÉ™ri Ã§Ä±xarÄ±r.






# CNN-in É™sas hissÉ™lÉ™ri

# 1. Input Layer

# ÅÉ™kilin daxil olduÄŸu qat (mÉ™sÉ™lÉ™n: 224Ã—224Ã—3).

# 2. Convolution Layer

# ÅÉ™kili filterlÉ™rlÉ™ (kernel) gÉ™zib xÃ¼susiyyÉ™tlÉ™ri (edges, forms) Ã§Ä±xarÄ±r.

# 3. ReLU Layer

# Aktivasiya funksiyasÄ±dÄ±r â€” mÉ™nfi dÉ™yÉ™rlÉ™ri sÄ±fÄ±rlayÄ±r, modeli qeyri-xÉ™tti edir.

# 4. Pooling Layer (Max/Average Pooling)

# ÅÉ™kili kiÃ§ildir (downsampling)

# Vacib mÉ™lumatÄ± saxlayÄ±r

# Qeyd: Pooling = Convolution + ReLU deyil.
# Pooling ayrÄ±ca bir qattÄ±r.

# 5. Flatten Layer

# 2D matrisi 1D vektora Ã§evirir ki, fully connected layer istifadÉ™ edÉ™ bilsin.

# 6. Fully Connected (Dense) Layer

# Son tÉ™snifatÄ± edir.
# MÉ™sÉ™lÉ™n: piÅŸik / it, rÉ™qÉ™m â†’ 0â€“9 vÉ™ s.





# CNN harada istifadÉ™ olunur?

# Ãœz tanÄ±ma (Face ID)

# Obyekt tanÄ±ma (YOLO, Tesla-nÄ±n kameralarÄ±)

# Tibb (rentgen analizi)

# Kamera tÉ™sviri yaxÅŸÄ±laÅŸdÄ±rma

# Ã‡atbotlarda OCR (ÅŸÉ™kildÉ™n mÉ™tn oxuma)

# Bir cÃ¼mlÉ™lik yekun

# ğŸ‘‰ CNN â€“ ÅŸÉ™killÉ™ri anlamaq Ã¼Ã§Ã¼n É™n gÃ¼clÃ¼ sÃ¼ni intellekt modelidir.






# â€œANN ÅŸÉ™kili dÃ¼z baÅŸa dÃ¼ÅŸmÃ¼r, Ã§Ã¼nki onu É™vvÉ™lcÉ™ parÃ§alayÄ±r.â€

# âœ”ï¸ MÉ™na dÃ¼zgÃ¼n â€“ ANN ÅŸÉ™kili 1D edÉ™rÉ™k strukturunu itirir.

# â€œ2D struktur, yaxÄ±nlÄ±q É™laqÉ™lÉ™ri, formalar hamÄ±sÄ± itir.â€

# âœ”ï¸ DÃ¼zgÃ¼n â€“ bu ANN-in gÃ¶rÃ¼ntÃ¼ Ã¼Ã§Ã¼n É™sas problemidir.

# â€œParÃ§alayÄ±b sonra analiz edir deyÉ™ problemdir.â€

# âœ”ï¸ BÉ™li, problem mÉ™hz budur â€“ 1D Ã§evrilmÉ™si nÉ™ticÉ™sindÉ™ mÉ™kan É™laqÉ™lÉ™ri qorunmur.






# â­ Edge Detection nÉ™dir?

# Edge Detection â€” ÅŸÉ™kildÉ™ kÉ™nar xÉ™tlÉ™ri tapmaq demÉ™kdir.

# YÉ™ni ÅŸÉ™kildÉ™ rÉ™ngin vÉ™ ya iÅŸÄ±qlÄ±ÄŸÄ±n kÉ™skin dÉ™yiÅŸdiyi yerlÉ™ri aÅŸkar edir.






# SNR=Bir mÉ™lumatda (ÅŸÉ™kil, audio, sensor, video) â€œfaydalÄ± siqnalâ€ sÉ™s-kÃ¼ydÉ™n gÃ¼clÃ¼dÃ¼r, ya yox â€” bunu Ã¶lÃ§mÉ™k Ã¼Ã§Ã¼n istifadÉ™ olunur.

# ÅÉ™kil analizi (Image Processing)
# Burada SNR istifadÉ™ olunur ki:
# ÅÉ™kil nÉ™ qÉ™dÉ™r tÉ™mizdir?
# Noise Ã§oxdur ya azdÄ±r?
# Filtr (Gaussian, Median vÉ™ s.) gÃ¶rÃ¼ntÃ¼nÃ¼ nÉ™ qÉ™dÉ™r tÉ™mizlÉ™di?
# Reconstruction algoritmi (SR, Autoencoder) nÉ™ticÉ™ni yaxÅŸÄ±laÅŸdÄ±rdÄ±?


# Daha yaxÅŸÄ± model Ã§Ä±xÄ±ÅŸÄ± Ã¼Ã§Ã¼n input keyfiyyÉ™tini Ã¶lÃ§mÉ™k.


# MLP sinir ÅŸÉ™bÉ™kÉ™si modelidir.

# Ne ferqleri var?
# SNR-in MLP ilÉ™ heÃ§ bir birbaÅŸa É™laqÉ™si yoxdur.
# SNR sadÉ™cÉ™ mÉ™lumatÄ±n sÉ™sli-sÉ™ssiz olub-olmadÄ±ÄŸÄ±nÄ± gÃ¶stÉ™rir.
# MLP isÉ™ o mÉ™lumatdan Ã¶yrÉ™nÉ™n modeldir.

# NiyÉ™ gÃ¶rÉ™ ÅŸÉ™kil analizindÉ™ SNR istifadÉ™ edirdik?
# Ã‡Ã¼nki ÅŸÉ™killÉ™r dÉ™ É™slindÉ™ siqnaldÄ±r â€” 2D siqnal.
#  HÉ™r piksel = mÉ™lumat.
#  ÅÉ™kildÉ™ sÉ™s-kÃ¼y (noise) varsa â†’ modelin gÃ¶rmÉ™si vÉ™ Ã¶yrÉ™nmÉ™si pislÉ™ÅŸir.
# Bu sÉ™bÉ™bdÉ™n ÅŸÉ™kil emalÄ± vÉ™ Computer Vision-da SNR Ã§ox kritikdir.
# ve sekillerimiz bezen temiz olmaya biler. Bu halda SNR:
# ÅÉ™klin nÉ™ qÉ™dÉ™r â€œtÉ™mizâ€ olduÄŸunu Ã¶lÃ§Ã¼r
# Noise-u azaltma metodlarÄ±nÄ±n effektivliyini mÃ¼qayisÉ™ etmÉ™yÉ™ imkan verir
# ModelÉ™ verÉ™cÉ™yin input-un keyfiyyÉ™tini yoxlamaq Ã¼Ã§Ã¼ndÃ¼r



#endregion


#region PythonAi17

# Lesson17:

# ResNet18= ResNet-18, 2015-ci ildÉ™ Microsoft Research tÉ™rÉ™findÉ™n yaradÄ±lmÄ±ÅŸ Residual Network ailÉ™sinÉ™ aid olan, 18 qatlÄ± (layer) bir Convolutional Neural Network-dir (CNN).
# BuradakÄ± â€œ18â€ sadÉ™cÉ™ â€” qatlarÄ±n sayÄ±dÄ±r.
# neye gore ResNet18?: ModelÉ™ â€œlayer-lÉ™ri keÃ§ib getmÉ™yÉ™â€ icazÉ™ verir â†’ bu da dÉ™rin ÅŸÉ™bÉ™kÉ™lÉ™rdÉ™ yaranan vanishing gradient problemini Ã¶ldÃ¼rÃ¼r.
# ResNet-18-in Ã¼stÃ¼nlÃ¼klÉ™ri
# YÃ¼ngÃ¼l vÉ™ sÃ¼rÉ™tli
# Az GPU RAM istÉ™yir
# Training-i stabil
# Overfitting az olur
# Transfer learning Ã¼Ã§Ã¼n Ã§ox É™lveriÅŸli
# Accuracy normaldÄ±r (ResNet50 qÉ™dÉ™r olmasa da)


#endregion